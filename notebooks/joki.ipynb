{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章 タイトル未定\n",
    "\n",
    "本章では文書分類モデルの作成を通じて自然言語処理で用いられる数々のPythonツールの利用方法を学びます。\n",
    "\n",
    "なお、動作確認は以下の環境で行いました。\n",
    "\n",
    "- Machine (AWS EC2 p2.xlargeインスタンス)\n",
    "    - OS: Ubuntu 16.04\n",
    "    - CPU: Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
    "    - RAM: 64GB \n",
    "    - GPU: NVIDIA Tesla K80\n",
    "- Python\n",
    "    - python: 3.7.5\n",
    "    - mecab-python3: 0.996.2\n",
    "    - torch (PyTorch): 1.3.1\n",
    "    - torchtext: 0.4.0\n",
    "    - transformers 2.3.0\n",
    "    - spaCy 2.2.3\n",
    "    - cupy 7.0.0\n",
    "    \n",
    "## 3.1 機械学習モデル開発のワークフローと本章で扱う内容\n",
    "\n",
    "文書分類のモデルは基本的に**教師あり学習**の枠組みで訓練します。つまり、図のようにテキストとラベルのペアで訓練データを用意します。例えばニュース記事があるとして、その記事はスポーツニュースなのか、芸能ニュースなのか、政治ニュースなのかを記事内の文章から分類したいとします。このときニュース記事の文章と、分類すべきカテゴリーの名前をペアとして扱います。\n",
    "\n",
    "![training.svg](./figures/training.svg)\n",
    "<center>図出典: https://spacy.io/usage/training</center>\n",
    "\n",
    "大まかにいうと大体以下の様な流れに沿って機械学習モデルの学習を進めていきます。\n",
    "\n",
    "1. 訓練用のデータセットを用意する\n",
    "2. 分類に用いる機械学習モデルを準備する\n",
    "3. モデルに訓練データのテキストを入力して予測値を得る\n",
    "4. モデルの予測と真のラベルを比較する\n",
    "5. 誤差を減らすようなモデルのパラメーター (重み) の更新値 (gradient) を計算する\n",
    "6. モデルのパラメーターを更新する\n",
    "7. 3から6を繰り返す\n",
    "\n",
    "具体的な手順に関しては次の節以降で見ていきましょう。\n",
    "\n",
    "## 3.2 文書分類ハンズオン\n",
    "\n",
    "ここではExplosion AIが開発する汎用的な自然言語処理ツールである **spaCy** と、Hugging Faceが開発するtransformerベースの現在最先端のモデルを簡単に利用するためのツールである **transformers** を扱ってニュース記事の分類モデルを作成します。\n",
    "\n",
    "### 3.2.1 本章で扱う主な自然言語処理ツールの解説\n",
    "\n",
    "#### 3.2.1.1 spaCy\n",
    "\n",
    "spaCy (https://spacy.io/) とはExplosion AIにより開発されている自然言語処理用のライブラリです。spaCyには事前学習済みの統計モデルと単語ベクトルが付属しており、50以上の言語の形態素解析（トークン化）がサポートされています。また、品詞タグ付け、依存関係解析、固有表現抽出、およびテキスト分類のための単語バッグや簡単な畳み込みニューラルネットワークモデルも備えています。MITライセンスの下でリリースされた商用のオープンソースソフトウェアです。\n",
    "\n",
    "spaCyのドキュメンテーション (https://spacy.io/usage/) に従ってインストールしてみましょう。環境によってインストールコマンドが異なるので適宜ドキュメンテーションを参考にしてください。ここではGPU付きのオプションでインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy[cuda]\n",
    "# pip install -U spacy  # GPUを利用しない場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCyと同時に、Explosion AIにより開発されているThinc (https://github.com/explosion/thinc) という機械学習ライブラリや、Preferred NetworksのCUDA対応のNumPy互換行列計算ライブラリであるCuPy (https://cupy.chainer.org/) などがインストールされます。\n",
    "\n",
    "日本語の形態素解析ツールのMeCab (http://taku910.github.io/mecab/) もインストールしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分かち書きのテストをしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すもも\n",
      "も\n",
      "もも\n",
      "も\n",
      "もも\n",
      "の\n",
      "うち\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank('ja')\n",
    "for word in nlp('すもももももももものうち'):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく単語ごとに分割してくれていますね。本章でのスコープからは外れますが、リクルートと国立国語研究所が開発した GiNZAをインストールするとspaCy経由で日本語文章の解析処理を簡単に行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"https://github.com/megagonlabs/ginza/releases/download/latest/ginza-latest.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GiNZAのモデルを利用すると品詞タグ付けのみならず、トークン間の依存関係ラベリングや固有表現抽出などを行うことができます。ここではトークン間の依存関係を図示する例を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'ja_ginza'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2bcdb4561ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ja_ginza'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'すもももももももものうち'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dep\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'ja_ginza'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "doc = nlp('すもももももももものうち')\n",
    "displacy.render(doc, style=\"dep\", options={\"compact\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GiNZAとspaCyに関してはオージス総研グループによる「はじめての自然言語処理　第4回 spaCy/GiNZA を用いた自然言語処理」 (https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part4.html) に詳しい解説がありますのでそちらを参照することをお勧めします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Transformers\n",
    "\n",
    "Transformersはtransformerベースの汎用アーキテクチャ （BERT、GPT-2、RoBERTa、XLM、DistilBert、XLNet、CTRL、...） を利用するためのオープンソースのシンプルなAPIを提供しています。開発はHugging Faceにより行われており、100以上の言語に対応した事前学習済みモデルが公開されています。ディープラーニングフレームワークとしてはGoogleのTensorFlow 2.0およびFaceBookが開発しているPyTorchに対応しています。ここではPyTorchを用いることにします。\n",
    "\n",
    "Transformersで用いることのできるモデルのリストはHugging Faceのホームページ (https://huggingface.co/models) にて公開されています。日本語用BERTモデルとしては、執筆時点 (2019年12月) では東北大学 乾・鈴木研究室が公開している以下の4つのモデルを利用可能です。\n",
    "\n",
    "-  `bert-base-japanese`:\n",
    "-  `bert-base-japanese-whole-word-masking`\n",
    "-  `bert-base-japanese-char`\n",
    "-  `bert-base-japanese-char-whole-word-masking`\n",
    "\n",
    "BERTには大きく分けて `BERT-Base` (12-layer, 768-hidden, 12-heads, 110M parameters) と `BERT-Large` (24-layer, 1024-hidden, 16-heads, 340M parameters) のふたつのアーキテクチャーがあります。上記のモデルは `BERT-Base` を日本語のWikipediaのデータを用いて訓練したものです。`bert-base-japanese` はMeCabとWordPieceと呼ばれる手法を用いてテキストの分かち書きを行った後に訓練されたものであり、`bert-base-japanese-char` ではテキストを文字ごとに分割しています。\n",
    "\n",
    "BERTの訓練時に行うタスクのひとつに、文章内のトークンをマスクし、そのトークンを予測する、というものがあります。例えば `\"He likes playing the piano.\"` という文章を `\"He likes [MASK] ##ing the piano.\"` という文章に変換し、`[MASK]` に含まれるトークンを予測します。なお、`##` から始まるトークンは接尾辞を表しています。このとき、単語に対応するトークンはまとめてマスクするのが Whole Word Masking と呼ばれる手法です。先ほどの文章を `\"He likes [MASK] [MASK] the piano.\"` のようにマスクして訓練したモデルが `bert-base-japanese-whole-word-masking` および、`bert-base-japanese-char-whole-word-masking` です。\n",
    "\n",
    "さて、transformersをインストールしてみましょう。環境によってインストールコマンドが異なります。https://pytorch.org/get-started/ を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019年12月現在、NVIDIAのGPUを搭載したLinuxマシンにAnacondaでPyTorchをインストールするコマンドは以下の通りです。\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# LinuxでかつGPUがない場合は conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchで自然言語処理を行うときに便利なライブラリであるtorchtextもインストールしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install torchtext -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformersのインストールもpipを用いて簡単に行えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、以降で補助的に利用するライブラリもインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn seaborn mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn\n",
    "- mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformersの `BertJapaneseTokenizer` を用いた日本語文章の分かち書きのテストもしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "tokenizer.tokenize('いつもプレゼンテーションの撮影に無音カメラアプリをご利用いただきありがとうございます。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 データセットの準備\n",
    "\n",
    "次に機械学習モデルの訓練の要であるデータセットの準備をします。ここではlivedoor ニュースコーパスの各段落の文章を入力としてニュースサービスのカテゴリ名を判別するという問題設定でデータセットを作成します。\n",
    "\n",
    "#### 3.2.2.1 livedoor ニュースコーパス\n",
    "\n",
    "今回は日本語における自然言語処理の試験用データセットとしてしばしば用いられる「livedoor ニュースコーパス」を用います。\n",
    "\n",
    "livedoorニュースはもともと株式会社ライブドアが運営するニュースサイトでしたが、株式会社ライブドアが旧ハンゲームジャパン株式会社であるNHN Japan株式会社に買収され、現在はNHN Japanが社名変更したLINE株式会社により運営されています。livedoorニュースの記事の一部には「クリエイティブ・コモンズライセンス『表示 – 改変禁止』」が適用されており、営利目的を含めて再配布可能となっています。該当するニュース記事を2012年9月上旬に株式会社ロンウイットが収集し、HTMLタグの除去などクリーニングを施した状態で公開しているのが「livedoor ニュースコーパス」です。\n",
    "\n",
    "livedoor ニュースコーパスは以下のリンクよりダウンロード可能です。\n",
    "\n",
    "https://www.rondhuit.com/download.html#ldcc\n",
    "\n",
    "オープンソースの全文検索システムApache Solrで扱いやすいようXML形式でニュースが格納されている `livedoor-news-data.tar.gz` と、シンプルに各々のニュースをテキストファイルとして扱っている `ldcc-20140209.tar.gz` が公開されています。\n",
    "\n",
    "今回は後者の `ldcc-20140209.tar.gz` をダウンロードしてください。`tar xzvf ldcc-20140209.tar.gz` などにより解凍すると `text` という名前のディレクトリが出てきます。以下のPythonスクリプトを実行するとコーパスのダウンロードと圧縮ファイルの解凍が行われ、カレントディレクトリに `text` ディレクトリが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# dataディレクトリの作成\n",
    "#os.makedirs('data', exist_ok=True)\n",
    "\n",
    "url = 'https://www.rondhuit.com/download/ldcc-20140209.tar.gz'\n",
    "file_name = 'ldcc-20140209.tar.gz'\n",
    "\n",
    "# dataディレクトリへのlivedoor ニュースコーパスのダウンロードと解凍\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    # tar.gzファイルを読み込み\n",
    "    with tarfile.open(file_name) as tar:\n",
    "        tar.extractall()\n",
    "    # tar.gzファイルを消去\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` ディレクトリの中身の構造は以下の通りです。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "├── it-life-hack\n",
    "├── kaden-channel\n",
    "├── livedoor-homme\n",
    "├── movie-enter\n",
    "├── peachy\n",
    "├── smax\n",
    "├── sports-watch\n",
    "└── topic-news\n",
    "```\n",
    "\n",
    "`dokujo-tsushin` から `topic-news` はディレクトリであり、それぞれにニュース記事のテキストが格納されています。先ほどのツリーの階層をひとつ深くしてみると以下の様になります。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "│   ├── LICENSE.txt\n",
    "│   ├── dokujo-tsushin-4778030.txt\n",
    "│   ├── dokujo-tsushin-4778031.txt\n",
    "│   ├── dokujo-tsushin-4782522.txt\n",
    "...（以下略）\n",
    "```\n",
    "\n",
    "ニュース提供元は以下の9つです。記事の本文の各段落だけを見て、その記事がどのカテゴリに属しているのか（独女通信のニュースなのか、ITライフハックのニュースなのか、など）を判別する文書分類モデルを作成するのが本章の目的です。（記事の本文を全て一度に入力すると問題として簡単すぎるので、ここでは段落ごとに分割して独立した文章として扱っています。）\n",
    "\n",
    "- 独女通信 (http://news.livedoor.com/category/vender/90/)\n",
    "- ITライフハック (http://news.livedoor.com/category/vender/223/)\n",
    "- 家電チャンネル (http://news.livedoor.com/category/vender/kadench/)\n",
    "- livedoor HOMME (http://news.livedoor.com/category/vender/homme/)\n",
    "- MOVIE ENTER (http://news.livedoor.com/category/vender/movie_enter/)\n",
    "- Peachy (http://news.livedoor.com/category/vender/ldgirls/)\n",
    "- エスマックス (http://news.livedoor.com/category/vender/smax/)\n",
    "- Sports Watch (http://news.livedoor.com/category/vender/208/)\n",
    "- トピックニュース (http://news.livedoor.com/category/vender/news/)\n",
    "\n",
    "ちなみに、上記サービスのうちいくつかはドメインが変わっていたり終了しているので一部リンクが切れています。それぞれの記事ファイル（dokujo-tsushin-4778030.txtなど）は以下のフォーマットで構成されています。\n",
    "\n",
    "- １行目: 記事のURL\n",
    "- ２行目: 記事の日付\n",
    "- ３行目: 記事のタイトル\n",
    "- ４行目以降： 記事の本文\n",
    "\n",
    "このままでは少し扱いづらいのでひとつのtsv (tab-separated values) にまとめます。次のスクリプトの実行には多少時間がかかります。私の環境では6分弱かかりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== processing dokujo-tsushin =====\n",
      "===== processing it-life-hack =====\n",
      "===== processing kaden-channel =====\n",
      "===== processing livedoor-homme =====\n",
      "===== processing movie-enter =====\n",
      "===== processing peachy =====\n",
      "===== processing smax =====\n",
      "===== processing sports-watch =====\n",
      "===== processing topic-news =====\n",
      "done\n",
      "CPU times: user 5min 31s, sys: 18.5 s, total: 5min 50s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# あまりに短い段落は除く\n",
    "minimum_sentence_length = 32\n",
    "\n",
    "# livedoor ニュースのサービス名のリスト\n",
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]\n",
    "# tsvファイルの各カラムのインデックス名のリスト\n",
    "index = ['url', 'datetime', 'title', 'body']\n",
    "\n",
    "# 空のPandasのDataFrameを準備\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# 各サービスのディレクトリでループ\n",
    "for service in services:\n",
    "    print('===== processing {} ====='.format(service))\n",
    "    # ニュース記事をすべて指定\n",
    "    # パスの例は './text/dokujo-tsushin/dokujo-tsushin-4778030.txt'\n",
    "    # LICENSE.txt は除外\n",
    "    wild_card = os.path.join('text', service, service + '*.txt')\n",
    "    file_paths = glob.glob(wild_card)\n",
    "    # 各ニュース記事のファイルパスでループ\n",
    "    for file_path in file_paths:\n",
    "        # ファイルを開いて一行ずつ読み込む\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # tsv のカラムを辞書型で用意\n",
    "            series_dict = {'service': service}\n",
    "            for num, line in enumerate(lines):\n",
    "                #line = line.replace('\\n', '')  # 改行を削除\n",
    "                # 0, 1, 2行目はそれぞれURL, 日付, 記事タイトルに相当\n",
    "                if num < len(index):\n",
    "                    series_dict[index[num]] = line\n",
    "                # 3行目以降は本文\n",
    "                elif line != '\\n' and line != '':\n",
    "                    series_dict['body'] += line\n",
    "                # lineが空（段落の境目もしくはファイルの末尾）の場合\n",
    "                else:\n",
    "                    if '関連記事' in series_dict['body']:\n",
    "                        pass\n",
    "                    elif '関連リンク' in series_dict['body']:\n",
    "                        pass\n",
    "                    # PandasのSeriesを作成し、DataFrameに追加していく\n",
    "                    elif len(series_dict['body']) > minimum_sentence_length:\n",
    "                        s = pd.Series(series_dict)\n",
    "                        df = df.append(s, ignore_index=True)\n",
    "                    # bodyを初期化\n",
    "                    series_dict['body'] = ''\n",
    "print('done')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した `DataFrame` の最初の5行と最後の5行だけ抜き出して表示してみましょう。\n",
    "それぞれの行がニュース記事のひとつの段落に対応しています。ニュース記事自体は計7367個ありますが、32文字以下の短い段落を除くと全部で56631個の段落がありことがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56628</th>\n",
       "      <td>藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56629</th>\n",
       "      <td>ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56630</th>\n",
       "      <td>一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1      「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...   \n",
       "2      ●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...   \n",
       "56628  藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...   \n",
       "56629  ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...   \n",
       "56630  一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...   \n",
       "\n",
       "                         datetime         service  \\\n",
       "0      2011-10-13T15:28:00+0900\\n  dokujo-tsushin   \n",
       "1      2011-10-13T15:28:00+0900\\n  dokujo-tsushin   \n",
       "2      2011-10-13T15:28:00+0900\\n  dokujo-tsushin   \n",
       "56628  2012-06-21T20:32:00+0900\\n      topic-news   \n",
       "56629  2012-06-21T20:32:00+0900\\n      topic-news   \n",
       "56630  2012-06-21T20:32:00+0900\\n      topic-news   \n",
       "\n",
       "                                            title  \\\n",
       "0              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "1              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "2              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "56628  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56629  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56630  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "\n",
       "                                                     url  \n",
       "0      http://news.livedoor.com/article/detail/593428...  \n",
       "1      http://news.livedoor.com/article/detail/593428...  \n",
       "2      http://news.livedoor.com/article/detail/593428...  \n",
       "56628  http://news.livedoor.com/article/detail/668154...  \n",
       "56629  http://news.livedoor.com/article/detail/668154...  \n",
       "56630  http://news.livedoor.com/article/detail/668154...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.head(3), df.tail(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各サービスごとの段落数を数えるには `pandas.Series.value_counts()` メソッドを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smax              9212\n",
       "it-life-hack      8400\n",
       "dokujo-tsushin    8296\n",
       "peachy            7934\n",
       "movie-enter       6524\n",
       "livedoor-homme    5329\n",
       "kaden-channel     3818\n",
       "topic-news        3603\n",
       "sports-watch      3515\n",
       "Name: service, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['service'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.Series.plot` を利用してグラフを作成することも可能です。ここでは `kind='bar'` で棒グラフを指定し、横軸のラベルを見やすい様に `rot=45` で45度回転し、y軸の範囲を `ylim=(0, 10000)` で0から10000に指定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fad1a6c7650>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df['service'].value_counts()).plot(kind='bar', rot=45, ylim=(0, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的にラベルは文字列のままでは扱いづらい（ことが多い）のでscikit-learnの `LabelEncoder` (`sklearn.preprocessing.LabelEncoder`) を用いて整数値に変換してあげます。処理後は `'dokujo-tsushin'` が `0` になり、`it-life-hack` が `1` になり、`kaden-channel` が `2` …といった様に変換されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56628</th>\n",
       "      <td>藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56629</th>\n",
       "      <td>ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56630</th>\n",
       "      <td>一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1      「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...   \n",
       "2      ●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...   \n",
       "56628  藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...   \n",
       "56629  ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...   \n",
       "56630  一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...   \n",
       "\n",
       "                         datetime  service  \\\n",
       "0      2011-10-13T15:28:00+0900\\n        0   \n",
       "1      2011-10-13T15:28:00+0900\\n        0   \n",
       "2      2011-10-13T15:28:00+0900\\n        0   \n",
       "56628  2012-06-21T20:32:00+0900\\n        8   \n",
       "56629  2012-06-21T20:32:00+0900\\n        8   \n",
       "56630  2012-06-21T20:32:00+0900\\n        8   \n",
       "\n",
       "                                            title  \\\n",
       "0              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "1              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "2              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "56628  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56629  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56630  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "\n",
       "                                                     url  \n",
       "0      http://news.livedoor.com/article/detail/593428...  \n",
       "1      http://news.livedoor.com/article/detail/593428...  \n",
       "2      http://news.livedoor.com/article/detail/593428...  \n",
       "56628  http://news.livedoor.com/article/detail/668154...  \n",
       "56629  http://news.livedoor.com/article/detail/668154...  \n",
       "56630  http://news.livedoor.com/article/detail/668154...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['service'] = le.fit_transform(df.service.values)\n",
    "pd.concat([df.head(3), df.tail(3)])  # 最初と最後の3行を抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`service` の列が文字列でなく非負の整数値になっていることに注目してください。\n",
    "ここで、scikit-learnの `train_test_split` (`sklearn.model_selection.train_test_split`) を用いてデータセットを「訓練データ」、「バリデーションデータ」、「テストデータ」に分割します。それぞれの役割は以下の通りです。\n",
    "\n",
    "- 訓練データ: 機械学習モデルの重みの更新に利用する学習データ\n",
    "- バリデーションデータ: 機械学習モデルの学習状況やハイパーパラメーターチューニングの良し悪しのチェックに用いるデータ\n",
    "- テストデータ: 最終的に機械学習モデルの性能評価に用いるデータ\n",
    "\n",
    "![holdout.png](./figures/holdout.png)\n",
    "\n",
    "実際の学習は訓練データのみを用います。他ふたつはあくまで性能評価のために用います。本章ではハイパーパラメーターチューニングは行いませんが、形式的にこの通り分割することにします。それぞれのデータ量の割合は適当に8:1:1としました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df[['body', 'service']]  # 本文とラベルのみ抽出\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` をCSV (Comma-Separated Value) やTSV (Tab-Separated Value) で保存するには `pandas.DataFrame.to_csv` メソッドを呼び出します。ひとつ目の引数 `path_or_buf` には保存先のファイルパス（もしくはファイルオブジェクト）を指定し、ふたつ目の引数 `sep` には列のセパレーターを指定します。デフォルトでは `sep=','` となっており、セパレーターはカンマ、つまり `DataFrame` はCSVで保存されます。自然言語処理を行う場合、データ内にカンマが含まれていることがあるのでしばしばセパレーターとしてはタブ (`\\t`) が用いられます。ここでは `DataFrame` をTSVの形式で保存します。\n",
    "\n",
    "デフォルトでは `index` 引数は `True` になっています。そのままにするとTSVファイルに行番号の数値（この場合0から56630）がひとつのカラムとして追加されます。必要ないので `index=False` としておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv', sep='\\t', index=False)\n",
    "val_df.to_csv('val.tsv', sep='\\t', index=False)\n",
    "test_df.to_csv('test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでデータセットを分割してTSVファイルとして保存できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 文書分類モデル\n",
    "\n",
    "ここでは単語バッグ、シンプルなCNN、そしてBERTをそれぞれ用いて文書分類を行ってみます。単語バッグとCNNのモデルはspaCyのAPIから利用できます。BERTはtransformersから利用します。訓練状況のモニタリングにはTensorBoardを用います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.1 単語バッグ  (bag-of-words)\n",
    "\n",
    "単語バッグとはデータセットのテキスト中の単語のヒストグラムのことです。つまり、それぞれの単語の出現数を特徴量として扱います。例えば \"how does it feel like to wake up in the sun\", \"how does it feel like to shine on everyone\" というふたつの文があったとします。この中の単語 (トークン) それぞれに番号を付けると例えば以下の様になります。\n",
    "\n",
    "`{0: 'how', 1: 'does', 2: 'it', 3: 'feel', 4: 'like', 5: 'to', 6: 'wake', 7: 'up', 8: 'in', 9: 'the', 10: 'sun', 11: 'shine', 12: 'on', 13: 'everyone'}` \n",
    "\n",
    "それぞれの文を単語バッグとして表現すると以下の様になります。トークンの番号に対応するインデックスにそのトークンの出現数を詰めたリストとも言えます。\n",
    "\n",
    "`[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]`\n",
    "\n",
    "`[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]`\n",
    "\n",
    "単語バッグを用いればテキストを、データセットに出現するトークン数だけ次元がある（この場合は14次元の）ベクトルとみなすことができます。トークンひとつごとに番号を割り当てるのではなく、連続するトークンの対や三つ組など複数個をひとまとめに扱う手法を **n-グラム (n-gram)** と呼びます。spaCyの単語バッグはデフォルトでは `ngram_size=1` となっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('train.tsv', delimiter='\\t')\n",
    "df_val = pd.read_csv('val.tsv', delimiter='\\t')\n",
    "df_test = pd.read_csv('test.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df_train.body\n",
    "val_texts = df_val.body\n",
    "test_texts = df_test.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニュース文章を分かち書きします。私の環境ではそれぞれ30秒、4秒、3秒ほどかかりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()  # GPUがない場合、この行はスキップ\n",
    "nlp = spacy.blank('ja')\n",
    "\n",
    "train_docs = list(nlp.pipe(train_texts))\n",
    "val_docs = list(nlp.pipe(val_texts))\n",
    "test_docs = list(nlp.pipe(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCyのAPIに合わせて正解ラベルを整形してあげましょう。訓練時に用いる `spacy.Language.update` メソッドはラベルデータを辞書型のリストとして受け取るのですが、キーに `'words', 'tags', 'heads', 'deps', 'entities', 'cats', 'links'` のどれかが存在することを前提としています。文書分類の場合は `'cats'` が必要です。猫ではなく、カテゴリーの略です。それぞれのデータに対するラベルは以下の様な構成であることが求められています。キー `'cats'` の値がまた辞書型で、分類すべきラベルのキーの値のみ `True` で他は `False` となります。\n",
    "\n",
    "```\n",
    "[\n",
    "\"\"\"データ#0\"\"\"\n",
    " {'cats': {'dokujo-tsushin': True,\n",
    "           'it-life-hack': False,\n",
    "           'kaden-channel': False,\n",
    "           'livedoor-homme': False,\n",
    "           'movie-enter': False,\n",
    "           'peachy': False,\n",
    "           'smax': False,\n",
    "           'sports-watch': False,\n",
    "           'topic-news': False}},\n",
    "\"\"\"データ#1\"\"\"\n",
    " {'cats': {'dokujo-tsushin': False,\n",
    "           'it-life-hack': True,\n",
    "           'kaden-channel': False,\n",
    "           'livedoor-homme': False,\n",
    "           'movie-enter': False,\n",
    "           'peachy': False,\n",
    "           'smax': False,\n",
    "           'sports-watch': False,\n",
    "           'topic-news': False}},\n",
    "\"\"\"データ#2以降\"\"\"\n",
    "...]\n",
    "```\n",
    "\n",
    "リスト内包表記と辞書内包表記を併用していてやや見づらいですが、以下の様にして `DataFrame` に対してループを回して整形します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]\n",
    "\n",
    "train_cats = [{'cats': {service: service == services[idx] for service in services}}\n",
    "              for idx in df_train.service]\n",
    "val_cats = [{'cats': {service: service == services[idx] for service in services}}\n",
    "            for idx in df_val.service]\n",
    "test_cats = [{'cats': {service: service == services[idx] for service in services}}\n",
    "             for idx in df_test.service]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちゃんと期待通りに整形できているか確かめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cats': {'dokujo-tsushin': False, 'it-life-hack': False, 'kaden-channel': False, 'livedoor-homme': True, 'movie-enter': False, 'peachy': False, 'smax': False, 'sports-watch': False, 'topic-news': False}}, {'cats': {'dokujo-tsushin': False, 'it-life-hack': False, 'kaden-channel': False, 'livedoor-homme': False, 'movie-enter': False, 'peachy': False, 'smax': True, 'sports-watch': False, 'topic-news': False}}]\n"
     ]
    }
   ],
   "source": [
    "print(train_cats[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題なければテキストとラベルのペアをリストに詰めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_docs, train_cats))\n",
    "val_data = list(zip(val_docs, val_cats))\n",
    "test_data = list(zip(test_docs, test_cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまででspaCyで文書分類を行うときのデータセットの準備は完了です。\n",
    "\n",
    "##### 文書分類モデルの訓練\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCyには自然言語処理のシーケンスとしてパイプラインという概念があります。\n",
    "![pipeline.svg](./figures/pipeline.svg)\n",
    "<center>図出典: https://spacy.io/usage/processing-pipelines</center>\n",
    "なお、前述のGiNZAのモデルを用いるとトークナイザーによる分かち書きだけでなく、品詞タグ付け、固有表現抽出、依存関係解析などの処理がパイプラインに含まれます。ここでは `nlp = spacy.blank('ja')` としてトークナイザー (MeCab) の処理のみ持ったパイプラインを指定しています。以下でパイプラインに文書分類モデルを `textcat` という名前で追加します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'textcat' not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe('textcat', \n",
    "                              config={'exclusive_classes': True, 'architecture': 'bow'})\n",
    "    nlp.add_pipe(textcat, last=True)  # パイプラインの末尾に追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'exclusive_classes': True` と指定するとモデルの出力層にソフトマックスが用いられます。つまり、モデルの出力がそれぞれのラベルに分類される確率として解釈できる様になります。なお、`'exclusive_classes': False` と指定すると出力層にはロジスティック関数が用いられます。排他的に分類するのではなく例えば、ニュース記事の分類時にこれはスポーツかつゴシップである、といった様に複数ラベルを割り当てたい時は後者を用います。`'architecture': 'bow'` で文書分類モデルの種類を単語バッグ (bag-of-words) に指定しています。\n",
    "\n",
    "次に、以下の様にしてモデルにラベルの情報を登録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add label dokujo-tsushin.\n",
      "Add label it-life-hack.\n",
      "Add label kaden-channel.\n",
      "Add label livedoor-homme.\n",
      "Add label movie-enter.\n",
      "Add label peachy.\n",
      "Add label smax.\n",
      "Add label sports-watch.\n",
      "Add label topic-news.\n"
     ]
    }
   ],
   "source": [
    "for service in services:\n",
    "    textcat.add_label(service)\n",
    "    print(\"Add label %s.\" % (service))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いよいよ訓練を行いますが、その前に訓練状況を確認するための評価関数を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(tokenizer, textcat, docs, cats, output_dict=False):\n",
    "    \"\"\"訓練時にモデルの性能を評価する関数\n",
    "    \n",
    "    引数:\n",
    "        tokenizer: パイプライン内に含まれるトークナイザー\n",
    "        textcat: 訓練対象の文書分類モデル\n",
    "        docs: 評価用データセットのテキストのリスト\n",
    "        cats: 評価用データセットのラベルのリスト\n",
    "              e.g. [{'cats': {'dokujo-tsushin': False, ...}}, {'cats': ...}]\n",
    "    返り値:\n",
    "        sklearn.metrics.classification_report: 各ラベルに対する性能の表\n",
    "            (str) if output_dict is False else (dict)\n",
    "    \"\"\"\n",
    "    # Trueのラベルの名前を y_true absのリストに詰める\n",
    "    # e.g. ['dokujo-tsushin', 'smax', 'peachy', ...]\n",
    "    y_true = [max(cat['cats'].items(), key=lambda x:x[1])[0] for cat in cats]\n",
    "    # 一番出力値が大きいラベルの名前を y_pred のリストに詰める\n",
    "    y_pred = []\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        prediction = max(doc.cats.items(), key=lambda x:x[1])[0]  # 予測のサービス名\n",
    "        y_pred.append(prediction)\n",
    "    return classification_report(y_true, y_pred, output_dict=output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、訓練を行いましょう。こちらのコードはspaCyのドキュメンテーション (https://spacy.io/usage/training#textcat) を参考にしています。大まかに以下の様な手順を踏んでいます。\n",
    "\n",
    "1. 訓練データに対してループを回す (ここではデータのミニバッチ化にspaCyの `minibatch` と `compunding` を用いる)\n",
    "2. `nlp.update` メソッドでモデルを更新する\n",
    "3. `evaluate`関数でモデルのパフォーマンスをチェックする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "===== iteration 1/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8a43bf83bc48a693c6ff8319659235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 9.2489\n",
      "val accuracy = 0.8001\n",
      "===== iteration 2/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d23507e1664f238c3ab14093d81d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.3077\n",
      "val accuracy = 0.8068\n",
      "===== iteration 3/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70594a8c5514251aeb1c6f34efabe67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2802\n",
      "val accuracy = 0.8102\n",
      "===== iteration 4/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9229743e7d33431bbc6de85ff9b39998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2576\n",
      "val accuracy = 0.8162\n",
      "===== iteration 5/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e614d950704041098c180156d15586a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2338\n",
      "val accuracy = 0.8169\n",
      "===== iteration 6/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8deee4d673fe41ed80bd6aff66d9c8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2159\n",
      "val accuracy = 0.8216\n",
      "===== iteration 7/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51481d96a4849d0bed025c00db65608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2046\n",
      "val accuracy = 0.8216\n",
      "===== iteration 8/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f524e7b9fc004512b2abb793842dd8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1951\n",
      "val accuracy = 0.8202\n",
      "===== iteration 9/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d17dccb13464a4d8cee6ee899715cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1866\n",
      "val accuracy = 0.8215\n",
      "===== iteration 10/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0250f82d1686464aa38e63aadbc2bb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1789\n",
      "val accuracy = 0.8222\n",
      "===== iteration 11/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfeafbb5f29487e9b90913661ae2ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1701\n",
      "val accuracy = 0.8231\n",
      "===== iteration 12/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd126ec7c5a548e0baf1784f460ad112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1626\n",
      "val accuracy = 0.8213\n",
      "===== iteration 13/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6813b0afb0954528ae27cd248178791c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1604\n",
      "val accuracy = 0.8224\n",
      "===== iteration 14/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc2473cc7e64501bd6643de0e0b5f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1537\n",
      "val accuracy = 0.8225\n",
      "===== iteration 15/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129695f019d1457e9bf87a0a526772f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1514\n",
      "val accuracy = 0.8227\n",
      "===== iteration 16/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b897ced374549c69bf577d35d569818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1489\n",
      "val accuracy = 0.8222\n",
      "===== iteration 17/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e913a0a62ec44e02b51059376e50c420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1469\n",
      "val accuracy = 0.8222\n",
      "===== iteration 18/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9088cd4394e445cab328f7a59962626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1426\n",
      "val accuracy = 0.8201\n",
      "===== iteration 19/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffce34047544079a7f45bcb32ea4733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1435\n",
      "val accuracy = 0.8201\n",
      "===== iteration 20/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b626f307c54175af49ebf668d70521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1380\n",
      "val accuracy = 0.8195\n",
      "===== iteration 21/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f511bf86241647d4a64eb2d878ccba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1368\n",
      "val accuracy = 0.8202\n",
      "===== iteration 22/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad126f039e242f4af93f760cdead745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1374\n",
      "val accuracy = 0.8185\n",
      "===== iteration 23/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c223bb4b53456fa5ac73f670830806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1376\n",
      "val accuracy = 0.8185\n",
      "===== iteration 24/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f6d5caf046402591b4ac6fb741c603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1326\n",
      "val accuracy = 0.8195\n",
      "===== iteration 25/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b12d0efb4341ceb723d38e7832f58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1340\n",
      "val accuracy = 0.8199\n",
      "===== iteration 26/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac24db721cb47cab3aaa8edc4774298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1333\n",
      "val accuracy = 0.8206\n",
      "===== iteration 27/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81949b1d26cf455fb7f69e26170516cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1297\n",
      "val accuracy = 0.8208\n",
      "===== iteration 28/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0712db0bb14a441a9c5a9e5e3966918a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1310\n",
      "val accuracy = 0.8206\n",
      "===== iteration 29/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecccc1224424c8b9d8b455f32b50894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1317\n",
      "val accuracy = 0.8211\n",
      "===== iteration 30/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26206bc6c8341c090a81cf4cdfa821e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1313\n",
      "val accuracy = 0.8206\n",
      "===== iteration 31/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f480cd037664ac787644e18edbf61db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1294\n",
      "val accuracy = 0.8208\n",
      "===== iteration 32/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9aac688691346d4b78853be1711e333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1323\n",
      "val accuracy = 0.8186\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.util import minibatch, compounding\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./logs/bow/' + datetime.today().isoformat(timespec='seconds'))\n",
    "\n",
    "# 'textcat' 以外のパイプラインを抽出 (今回は空)\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "# エポック数（何回データセット全体に対してループを回すか）\n",
    "n_epochs = 32\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # textcat のみを訓練する\n",
    "    # >>> nlp.pipeline\n",
    "    # [('textcat', <spacy.pipeline.pipes.TextCategorizer object at 0x7f62703ee790>)]\n",
    "    textcat = nlp.pipeline[-1][-1]\n",
    "    optimizer = textcat.begin_training()\n",
    "    print('Training the model...')\n",
    "    # ミニバッチサイズのスケジューリング https://arxiv.org/abs/1711.00489\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)  # サイズ4から始めて上限32まで1.001倍していく\n",
    "    num_samples = len(train_data)\n",
    "    for epoch in range(n_epochs):\n",
    "        print('===== iteration {}/{} ====='.format(epoch+1, n_epochs))\n",
    "        losses = {}\n",
    "        # 訓練データをシャッフルしてミニバッチ化する\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)  # generator\n",
    "        processed = 0\n",
    "        for batch in tqdm(batches):\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "        # spaCyでは重みの移動平均をトラックしている\n",
    "        # モデルを利用する際は重みの最新値でなく平均値を利用\n",
    "        # cf. https://www.aclweb.org/anthology/P04-1015/\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            print('val loss = {:.4f}'.format(losses['textcat']))\n",
    "            # TensorBoard用のログ記録\n",
    "            writer.add_scalar('Loss vs Epoch/val', losses['textcat'], epoch+1)\n",
    "            # バリデーションデータに対してモデルを評価する\n",
    "            report = evaluate(nlp.tokenizer, textcat, val_docs, val_cats, output_dict=True)\n",
    "            print('val accuracy = {:.4f}'.format(report['accuracy']))\n",
    "            # TensorBoard用のログ記録\n",
    "            writer.add_scalar('Accuracy vs Epoch/val', report['accuracy'], epoch+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別の端末で `$ tensorboard --logdir=./logs` のようにしてTensorBoardを立ち上げ、Google Chrome等のウェブブラウザで `http://localhost:6006` (ポート番号は `tensorboard` コマンドの出力を確認) にアクセスするとTensorBoardのUIを表示できます。これにより訓練状況のモニタリングを行うことができます。今回はバリデーションデータに対するエポックごとの損失関数の値 (Loss vs Epochs) と正解率 (Accuracy vs Epochs) をグラフ化しています。\n",
    "\n",
    "訓練が終わったらテストデータに対して性能評価をしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.79      0.81      0.80       788\n",
      "  it-life-hack       0.84      0.86      0.85       834\n",
      " kaden-channel       0.70      0.61      0.65       398\n",
      "livedoor-homme       0.75      0.72      0.73       538\n",
      "   movie-enter       0.88      0.87      0.87       699\n",
      "        peachy       0.77      0.81      0.79       770\n",
      "          smax       0.88      0.91      0.89       902\n",
      "  sports-watch       0.90      0.83      0.86       363\n",
      "    topic-news       0.84      0.81      0.82       372\n",
      "\n",
      "      accuracy                           0.82      5664\n",
      "     macro avg       0.82      0.80      0.81      5664\n",
      "  weighted avg       0.82      0.82      0.82      5664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate(nlp.tokenizer, textcat, test_docs, test_cats)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`accuracy` の行を見ると私の環境では0.82、つまり正解率が82%であることがわかります。\n",
    "\n",
    "訓練したモデルを保存するには `spacy.Language.to_disk` メソッドを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.use_params(optimizer.averages):\n",
    "    nlp.to_disk('bow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆に、保存したモデルを利用するには `spacy.load` メソッドを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label is livedoor-home || {'dokujo-tsushin': 0.02244236133992672, 'it-life-hack': 0.002831406891345978, 'kaden-channel': 0.00010195144568569958, 'livedoor-homme': 0.9678583145141602, 'movie-enter': 8.759806405578274e-06, 'peachy': 0.0034303395077586174, 'smax': 0.003178115701302886, 'sports-watch': 0.00012975306890439242, 'topic-news': 1.8902119336416945e-05}\n",
      "true label is smax || {'dokujo-tsushin': 9.367265363380284e-08, 'it-life-hack': 0.005356281995773315, 'kaden-channel': 0.022429993376135826, 'livedoor-homme': 0.0006789625622332096, 'movie-enter': 8.38480809761677e-06, 'peachy': 4.876298135059187e-06, 'smax': 0.9715030193328857, 'sports-watch': 7.972904541020398e-07, 'topic-news': 1.752505704644136e-05}\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('bow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しにテストデータの中の、あえて一段落でなく、一文を分類してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label is livedoor-home || {'dokujo-tsushin': 0.02244236133992672, 'it-life-hack': 0.002831406891345978, 'kaden-channel': 0.00010195144568569958, 'livedoor-homme': 0.9678583145141602, 'movie-enter': 8.759806405578274e-06, 'peachy': 0.0034303395077586174, 'smax': 0.003178115701302886, 'sports-watch': 0.00012975306890439242, 'topic-news': 1.8902119336416945e-05}\n",
      "true label is smax || {'dokujo-tsushin': 9.367265363380284e-08, 'it-life-hack': 0.005356281995773315, 'kaden-channel': 0.022429993376135826, 'livedoor-homme': 0.0006789625622332096, 'movie-enter': 8.38480809761677e-06, 'peachy': 4.876298135059187e-06, 'smax': 0.9715030193328857, 'sports-watch': 7.972904541020398e-07, 'topic-news': 1.752505704644136e-05}\n"
     ]
    }
   ],
   "source": [
    "# テストデータ内の livedoor-homme のニュースの一文\n",
    "doc = nlp('転職者なら誰でも気になる採用する側の心理')\n",
    "print('true label is livedoor-home ||', doc.cats)\n",
    "# テストデータ内の smax のニュースの一段落\n",
    "doc = nlp('ARROWS X F-10Dが7月20日に発売')\n",
    "print('true label is smax ||', doc.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "きちんと正しいラベルに対応する出力値が大きくなっていますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.2 畳み込みニューラルネットワーク\n",
    "\n",
    "画像処理の分野で広く用いられている畳み込みニューラルネットワーク (Convolutional Neural Network、以下CNN) を自然言語処理のタスクに用いるのに違和感を感じる読者も多いかもしれません。しかし、テキストもトークンをベクトル化して並べたものと扱えば画像と同じく数値の行列としてみなせるのです。\n",
    "\n",
    "spaCyが提供する `simple_cnn` アーキテクチャーは大まかにいうと、トークンの埋め込み層 (embedding layer)、デフォルトでは4層の畳み込み層、ソフトマックスなどの分類層から構成されています。\n",
    "\n",
    "まずは先ほど利用した単語バッグモデルをパイプラインから削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('textcat', <spacy.pipeline.pipes.TextCategorizer at 0x7fece4c9c9d0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe('textcat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほどと同様に `simple_cnn` モデルをパイプラインの末尾に配置し、ラベルを登録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add label dokujo-tsushin.\n",
      "Add label it-life-hack.\n",
      "Add label kaden-channel.\n",
      "Add label livedoor-homme.\n",
      "Add label movie-enter.\n",
      "Add label peachy.\n",
      "Add label smax.\n",
      "Add label sports-watch.\n",
      "Add label topic-news.\n"
     ]
    }
   ],
   "source": [
    "if 'textcat' not in nlp.pipe_names:\n",
    "    # 今回は 'architecture': 'simple_cnn'\n",
    "    textcat = nlp.create_pipe('textcat', config={'exclusive_classes': True, 'architecture': 'simple_cnn'})\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "for label in services:\n",
    "    textcat.add_label(label)\n",
    "    print('Add label %s.' % (label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとは単語バッグのときと全く同じ行程でCNNモデルの訓練を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "===== iteration 1/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a54b627ea0446c90c9f2c2ab441d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 26.5601\n",
      "val accuracy = 0.7477\n",
      "===== iteration 2/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8f5cb662fa45eabc576f28b3ee9b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.4575\n",
      "val accuracy = 0.7906\n",
      "===== iteration 3/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53ca85eb676416f87286345b9c40462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.3755\n",
      "val accuracy = 0.8012\n",
      "===== iteration 4/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d907132b40044896be765b91e0b64008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.3218\n",
      "val accuracy = 0.8107\n",
      "===== iteration 5/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85895a55f4af490bbd1969c918f5a5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2808\n",
      "val accuracy = 0.8206\n",
      "===== iteration 6/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e520e3e162404794ac500c396661e04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2477\n",
      "val accuracy = 0.8243\n",
      "===== iteration 7/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7e9da8764e49a79c31e4afaedac0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2265\n",
      "val accuracy = 0.8266\n",
      "===== iteration 8/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a872838f83114e3ba4e4ee36c63e4353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.2048\n",
      "val accuracy = 0.8294\n",
      "===== iteration 9/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaeeddc1f0443dd9fed0c9d1489d7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1865\n",
      "val accuracy = 0.8312\n",
      "===== iteration 10/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8a586c6aca4f52b63dc0da30ae34ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1756\n",
      "val accuracy = 0.8374\n",
      "===== iteration 11/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ba471f9b4f48dbbfb753c7fcf18011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1617\n",
      "val accuracy = 0.8377\n",
      "===== iteration 12/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879f2f6fc0124130a61fe0fab078d60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1526\n",
      "val accuracy = 0.8360\n",
      "===== iteration 13/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4631de5ad17347be88c129a7a41dcb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1404\n",
      "val accuracy = 0.8381\n",
      "===== iteration 14/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d88f7e13fad4ab68c340d83e34f2852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1326\n",
      "val accuracy = 0.8363\n",
      "===== iteration 15/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ece8efdd0b049e3b32a8ad822c0fe74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1248\n",
      "val accuracy = 0.8374\n",
      "===== iteration 16/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49edfe8d60ca4d5493969fdfb8cfe667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1164\n",
      "val accuracy = 0.8393\n",
      "===== iteration 17/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bc48826a6f45e39defb83863eb8b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1144\n",
      "val accuracy = 0.8391\n",
      "===== iteration 18/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758dae04c6b149c2813bf983be394be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1100\n",
      "val accuracy = 0.8384\n",
      "===== iteration 19/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7243af4ba9fa415687bf0b30817d2c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1036\n",
      "val accuracy = 0.8375\n",
      "===== iteration 20/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c659f4d86e6e4445ae71fcd2c3755935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.1024\n",
      "val accuracy = 0.8409\n",
      "===== iteration 21/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8aef07c5ea4418b51c29dc91104f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0954\n",
      "val accuracy = 0.8425\n",
      "===== iteration 22/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44f8a4f49a04faf93dd8b1146c9c551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0955\n",
      "val accuracy = 0.8458\n",
      "===== iteration 23/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f7d76f50f7493c806d8f4745690bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0917\n",
      "val accuracy = 0.8441\n",
      "===== iteration 24/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a937f176d5114f5480128dd401a2121b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0856\n",
      "val accuracy = 0.8446\n",
      "===== iteration 25/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3760db45c8d48e6994b9ce2278dac68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0860\n",
      "val accuracy = 0.8451\n",
      "===== iteration 26/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5671ea3359c144228ca13fb41b0234a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0821\n",
      "val accuracy = 0.8487\n",
      "===== iteration 27/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb85b020cefa4b7a8bb00b985021697a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0817\n",
      "val accuracy = 0.8471\n",
      "===== iteration 28/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864f2c1c2a024f68b5588adbe8269bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0764\n",
      "val accuracy = 0.8473\n",
      "===== iteration 29/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcd947d650247429b8249be8e731c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0737\n",
      "val accuracy = 0.8457\n",
      "===== iteration 30/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d576ecbd13436ebe51caddf0295bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0735\n",
      "val accuracy = 0.8462\n",
      "===== iteration 31/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcc6791dadd40ca9c77b4de85c8b724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0689\n",
      "val accuracy = 0.8469\n",
      "===== iteration 32/32 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d32b4f284c4d4b940f7a9b1b16bb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val loss = 0.0678\n",
      "val accuracy = 0.8485\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.util import minibatch, compounding\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./logs/simple_cnn/' + datetime.today().isoformat(timespec='seconds'))\n",
    "\n",
    "# 'textcat' 以外のパイプラインを抽出 (今回は空)\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "# エポック数（何回データセット全体に対してループを回すか）\n",
    "n_epochs = 32\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # textcat のみを訓練する\n",
    "    # >>> nlp.pipeline\n",
    "    # [('textcat', <spacy.pipeline.pipes.TextCategorizer object at 0x7f62703ee790>)]\n",
    "    textcat = nlp.pipeline[-1][-1]\n",
    "    optimizer = textcat.begin_training()\n",
    "    print('Training the model...')\n",
    "    # ミニバッチサイズのスケジューリング https://arxiv.org/abs/1711.00489\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)  # サイズ4から始めて上限32まで1.001倍していく\n",
    "    num_samples = len(train_data)\n",
    "    for epoch in range(n_epochs):\n",
    "        print('===== iteration {}/{} ====='.format(epoch+1, n_epochs))\n",
    "        losses = {}\n",
    "        # 訓練データをシャッフルしてミニバッチ化する\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)  # generator\n",
    "        processed = 0\n",
    "        for batch in tqdm(batches):\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "        # spaCyでは重みの移動平均をトラックしている\n",
    "        # モデルを利用する際は重みの最新値でなく平均値を利用\n",
    "        # cf. https://www.aclweb.org/anthology/P04-1015/\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            print('val loss = {:.4f}'.format(losses['textcat']))\n",
    "            # TensorBoard用のログ記録\n",
    "            writer.add_scalar('Loss vs Epoch/val', losses['textcat'], epoch+1)\n",
    "            # バリデーションデータに対してモデルを評価する\n",
    "            report = evaluate(nlp.tokenizer, textcat, val_docs, val_cats, output_dict=True)\n",
    "            print('val accuracy = {:.4f}'.format(report['accuracy']))\n",
    "            # TensorBoard用のログ記録\n",
    "            writer.add_scalar('Accuracy vs Epoch/val', report['accuracy'], epoch+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じくTensorBoardで訓練状況を確認しつつ、訓練が終わったらテストデータに対して性能評価をしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.81      0.86      0.83       788\n",
      "  it-life-hack       0.86      0.85      0.85       834\n",
      " kaden-channel       0.70      0.67      0.68       398\n",
      "livedoor-homme       0.82      0.70      0.76       538\n",
      "   movie-enter       0.89      0.88      0.88       699\n",
      "        peachy       0.83      0.84      0.84       770\n",
      "          smax       0.89      0.92      0.90       902\n",
      "  sports-watch       0.85      0.88      0.86       363\n",
      "    topic-news       0.80      0.81      0.81       372\n",
      "\n",
      "      accuracy                           0.84      5664\n",
      "     macro avg       0.83      0.82      0.82      5664\n",
      "  weighted avg       0.84      0.84      0.84      5664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate(nlp.tokenizer, textcat, test_docs, test_cats)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私の環境では `accuracy` は0.84、つまり正解率84%でした。単語バッグのときは82%だったので2ポイントの改善が見られました。モデルを保存するには `spacy.Language.to_disk` メソッドを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.use_params(optimizer.averages):\n",
    "    nlp.to_disk('simple_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.3 BERT\n",
    "\n",
    "ここからはspaCyではなくtransformersを用います。\n",
    "\n",
    "transformersはその名の通り **Transformer** (https://arxiv.org/abs/1706.03762) をベースにしたBERTなどの事前訓練済みモデルを簡単に利用するためのツールです。Transformer自体は \"Attention Is All You Need\" というセンセーショナルなタイトルの論文として2017年に発表されたGoogleのニューラルネットワークモデルです。BERTとは、ざっくり言うとTransformerを積み重ねたモデルです。BERTの論文 \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" (https://arxiv.org/abs/1810.04805) は2018年にGoogleから発表されました。原論文においてはBERTをBookCorpus (https://github.com/soskek/bookcorpus) とWikipedia (https://www.wikipedia.org/) のデータを用いて事前訓練し、次の表の各タスクのデータセットに対してファインチューニングすることで当時最高 (State Of The Art) のスコアを叩き出したことで話題になりました。 \n",
    "\n",
    "|タスク|概要|前SOTA|BERT|\n",
    "|:----|:----|:----:|:----:|\n",
    "|GLUE|8種の言語理解タスク|75.2|81.9|\n",
    "|1. MNLI|2入力文の含意/矛盾/中立を判定|82.1|86.7|\n",
    "|2. QQP|2質問文が意味的に等価か判定|70.3|72.1|\n",
    "|3. QNLI|SQuADの改変．陳述文が質問文の解答を含むか判定|88.1|91.1|\n",
    "|4. SST-2|映画レビューの入力文のネガポジを判定|91.3|94.9|\n",
    "|5. CoLA|入力文が言語的に正しいか判定|45.4|60.5|\n",
    "|6. STS-B|ニュース見出しの2入力文の意味的類似性をスコア付け|80.0|86.5|\n",
    "|7. MRPC|ニュース記事の2入力文の意味的等価性を判定|82.3|89.3|\n",
    "|8. RTE|2入力文の含意を判定|56.0|70.1|\n",
    "|SQuAD|質疑応答タスク．陳述文から質問文の解答を抽出|91.7|93.2|\n",
    "|CoNLL|固有表現抽出タスク．単語に人物/組織/位置のタグ付け|92.6|92.8|\n",
    "|SWAG|入力文に後続する文を4つの候補文から選択|59.2|86.3|\n",
    "\n",
    "<center>表出典: https://speakerdeck.com/ryobot/menhera-chan</center>\n",
    "\n",
    "あたかも画像処理の領域におけるImageNetデータセットで事前訓練したモデルのように、ある程度汎用的な特徴量抽出器として用いることができると期待されています。Wikipediaのような大きなデータセットを用いて訓練することで、入力のテキストを、目的のタスクを解くのに効率的な「表現」 (ベクトル) へと変換する役割をBERTないし多数提案されている進化版のモデルが担ってくれるのです。\n",
    "\n",
    "ただし、BERTの事前訓練は非常に高コストであり、原論文ではGoogleが開発しているTPU (Tensor Processing Unit) を16台用いて4日かかったと書いています。ですが、前述の通りありがたいことに東北大学 乾・鈴木研究室が日本語のWikipediaで事前訓練したモデル (https://github.com/cl-tohoku/bert-japanese) を公開しています。こちらのモデルはHugging Faceのリポジトリに登録されており、transformersから利用することができます。ここでは、`bert-base-japanese-whole-word-masking` と名付けられているモデルを利用してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "net = BertForSequenceClassification.from_pretrained('bert-base-japanese-whole-word-masking', num_labels=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数 `num_labels` を、livedoor ニュースコーパスのカテゴリー数である9に指定しています。こうすることで9カテゴリー分類のモデルとしてセットアップされます。GPUが使える場合は以下のようにしてモデルをGPUのメモリに転送しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみにこのニューラルネットワークの構造をnetron (https://github.com/lutzroeder/netron) というツールを用いて可視化すると次のようになります。\n",
    "<img src=\"./figures/bert_classifier_netron.png\" alt=\"bert_classifier_netron\" width=\"150\">\n",
    "BERTモデルの構造が `BertModel` に押し込められているため、やけにシンプルに見えますが、ここではあまり深く考えないようにします。\n",
    "\n",
    "PyTorchを用いてディープラーニングを実装する際には、まず入力するデータとそのラベルなどをペアにして保持する `DataSet` というクラスと、そのデータに対してどのようにループを回すかを設定する `DataLoader` というクラスを作成します。\n",
    "\n",
    "ここでは、上記の作業を支援してくれるPyTorchの自然言語処理用パッケージの `torchtext` を使用します。なお、以降のコードはマイナビ出版の「つくりながら学ぶ！PyTorchによる発展ディープラーニング」を参考にさせていただいています。\n",
    "\n",
    "##### データの前処理\n",
    "\n",
    "最初に、分かち書き用のトークナイザーを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、日本語文章の前処理と分かち書きを合体させた関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私', 'の', '年', '##収', 'は', '00', '万', 'です', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import mojimoji\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "        # 半角、全角の変換\n",
    "        text = mojimoji.han_to_zen(text)\n",
    "        # 改行、半角スペース、全角スペースを削除\n",
    "        text = re.sub('\\r', '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('　', '', text)\n",
    "        text = re.sub(' ', '', text)\n",
    "        # 数字文字の一律「0」化\n",
    "        text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
    "        return tokenizer.tokenize(text)\n",
    "    \n",
    "# 動作確認\n",
    "text = '私の年収は53万です。'\n",
    "print(tokenizer_with_preprocessing(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように自然言語処理ではしばしば、解きたいタスクに数値の絶対値が関係しない場合、すべて0に置き換えるという前処理が行われます。\n",
    "\n",
    "`torchtext.data.Field` を利用すれば、データに対する前処理やその結果の管理をよしなにやってくれます。本文とラベルに対してそれぞれ `Field` オブジェクトを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "TEXT = Field(\n",
    "    sequential=True,                        # データの長さが可変か\n",
    "    tokenize=tokenizer_with_preprocessing,  # トークナイザーの関数の指定\n",
    "    use_vocab=True,                         # 語彙 (Vocabオブジェクト) を利用するか (後述)\n",
    "    lower=False,                            # アルファベットを大文字から小文字に変換するか\n",
    "    include_lengths=True,                   # 各データのトークン数のリストを保持するか\n",
    "    batch_first=True,                       # データのテンソルの0次元目をミニバッチの次元にするか\n",
    "    fix_length=512,                         # 全テキストの長さを固定するか (512はbert-japaneseの仕様)\n",
    "    init_token='[CLS]',                     # 文章の開始を表すトークン\n",
    "    eos_token='[SEP]',                      # 文章の終了を表すトークン\n",
    "    pad_token='[PAD]',                      # 長さ調整のパディングに用いるトークン\n",
    "    unk_token='[UNK]'                       # 未知語を表すトークン\n",
    ")\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを読み込む際に行う処理を定義したらデータを実際に読み込みます。今回はデータをTSVファイルで保存していたので、`torchtext.data.TabularDataset` を利用します。`fields` 引数ではTSVファイルの各カラムの名前と `Field` オブジェクト (ここでは `TEXT` もしくは `LABEL`) のペアのタプルを列挙します。なお、`(name, None)` のようにすればそのカラムは無視されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train, val, test = TabularDataset.splits(\n",
    "    path='.', train='train.tsv', validation='val.tsv', test='test.tsv', format='tsv', \n",
    "    fields=[('body', TEXT), ('service', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  トークンの数値化\n",
    "\n",
    "テキストはそのままでは機械学習モデルから扱えないので、何かしらの方法で数値形式に変換する必要があります。単語バッグの例ではトークンごとにインデックスを振り、CNNの例では埋め込み表現 (ベクトル) として扱う方法を紹介しました。今回はBERTのトークナイザーに付随している語彙を利用します。日本語BERTのトークナイザーの語彙には `transformers.BertJapaneseTokenizer.vocab` でアクセスできます。型が `OrderedDict` なので一部のみ表示するにはややトリッキーな処理が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4, 'の': 5, '、': 6, 'に': 7, '。': 8, 'は': 9, 'た': 10, 'を': 11, 'で': 12, 'と': 13, 'が': 14, 'し': 15, 'て': 16, '1': 17, 'な': 18, '年': 19}\n",
      "vocab size is 32000\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "print(dict(itertools.islice(tokenizer.vocab.items(), 20)))\n",
    "print('vocab size is', len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この語彙を `TEXT` の `Field` の語彙にセットします。`stoi` は\"string to integer\"、つまり文字列と整数値の対応付けを表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT.build_vocab(train, min_freq=1)  # 訓練データに含まれるトークンから語彙を作成する場合\n",
    "TEXT.vocab.stoi = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator\n",
    "\n",
    "batch_size = 32\n",
    "train_iter = Iterator(train, batch_size, train=True, device=device)\n",
    "val_iter = Iterator(val, batch_size, train=False, sort=False, device=device)\n",
    "test_iter = Iterator(test, batch_size, train=False, sort=False, device=device)\n",
    "# あとで扱いやすいように辞書にまとめておく\n",
    "iterator_dict = {'train': train_iter, 'val': val_iter, 'test': test_iter}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERTのファインチューニングのための設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. すべてのパラメーターに対して勾配計算を False にする\n",
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False\n",
    "# 2. BertModel の最後のレイヤーのみ勾配計算 True にする\n",
    "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True\n",
    "# 3. 分類器も勾配計算 True にする\n",
    "for name, param in net.classifier.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamアルゴリズムでそれぞれのパラメータを更新\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "    {'params': net.classifier.parameters(), 'lr': 5e-5}\n",
    "], betas=(0.9, 0.999))\n",
    "# 損失関数の設定\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./logs/bert/' + datetime.today().isoformat(timespec='seconds'))\n",
    "\n",
    "def train_model(net, iterator_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    iteration = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for batch in iterator_dict[phase]:\n",
    "                inputs = batch.body[0]\n",
    "                labels = batch.service\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    loss, logit = net(input_ids=inputs, labels=labels)\n",
    "                    _, preds = torch.max(logit, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            acc = (torch.sum(preds == labels.data)).double() / batch_size\n",
    "                            print('iteration {} || Loss: {:.4f} || acc {}'.format(\n",
    "                                iteration, loss.item(), acc.item()))\n",
    "                            writer.add_scalar(\"Loss vs Iteration/{}\".format(phase), loss.item(), iteration)\n",
    "                            writer.add_scalar(\"Accuracy vs Iteration/{}\".format(phase), acc.item(), iteration)\n",
    "                        iteration += 1\n",
    "                    \n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    #print(preds, labels.data)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = epoch_loss / len(iterator_dict[phase].dataset)\n",
    "        epoch_acc = epoch_corrects.double() / len(iterator_dict[phase].dataset)\n",
    "        writer.add_scalar(\"Loss vs Epoch/{}\".format(phase), epoch_loss, epoch + 1)\n",
    "        writer.add_scalar(\"Accuracy vs Epoch/{}\".format(phase), epoch_acc, epoch + 1)\n",
    "        \n",
    "        print('Epoch {}/{} | {} | Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            epoch + 1, num_epochs, phase, epoch_loss, epoch_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100 \n",
    "net_trained = train_model(net, iterator_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価と比較\n",
    "\n",
    "まずBoWからはじめよう\n",
    "\n",
    "## まとめ\n",
    "\n",
    "BoW、CNN、BERT\n",
    "\n",
    "難しいタスクならBERT試すのもありかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [(Part 1) tensorflow2でhuggingfaceのtransformersを使ってBERTを文書分類モデルに転移学習する](https://tksmml.hatenablog.com/entry/2019/10/22/215000)\n",
    "- [(Part 2) tensorflow 2 でhugging faceのtransformers公式のBERT日本語学習済みモデルを文書分類モデルにfine-tuningする](https://tksmml.hatenablog.com/entry/2019/12/15/090900)\n",
    "- [All Models and checkpoints](https://huggingface.co/models)\n",
    "- [Working with GPU packages](https://docs.anaconda.com/anaconda/user-guide/tasks/gpu-packages/)\n",
    "- [gensimとPyTorchを使ったlive doorニュースコーパスのテキスト分類](https://www.pytry3g.com/entry/2018/04/03/194202)\n",
    "- [bert-japanese](https://github.com/cl-tohoku/bert-japanese)\n",
    "- [DocumentClassificationUsingBERT-Japanese](https://github.com/nekoumei/DocumentClassificationUsingBERT-Japanese)\n",
    "- [torchtext](https://torchtext.readthedocs.io/en/latest/index.html)\n",
    "- [FX予測 : PyTorchのBERTで経済ニュース解析](https://qiita.com/THERE2/items/8b7c94787911fad8daa6)\n",
    "- [torchtextで簡単にDeepな自然言語処理](https://qiita.com/itok_msi/items/1f3746f7e89a19dafac5)\n",
    "- [transformers](https://github.com/huggingface/transformers)\n",
    "- [BERTを使った文章要約 [身内向け]](https://qiita.com/IwasakiYuuki/items/25f5bbcde4f82dff7f1a)\n",
    "- [MeCab + Gensim による日本語の自然言語処理](https://www.koi.mashykom.com/nlp.html)\n",
    "- [論文解説 Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (GNMT)](http://deeplearning.hatenablog.com/entry/gnmt)\n",
    "- [BERT with SentencePiece で日本語専用の pre-trained モデルを学習し、それを基にタスクを解く](https://techlife.cookpad.com/entry/2018/12/04/093000)\n",
    "- [はじめての自然言語処理](https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
