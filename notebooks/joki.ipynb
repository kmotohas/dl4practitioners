{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章\n",
    "\n",
    "## 機械学習モデル開発のワークフローと本章で扱う内容\n",
    "\n",
    "なお、動作確認は以下の環境で行いました。\n",
    "\n",
    "- Machine (AWS EC2 p2.xlargeインスタンス)\n",
    "    - OS: Ubuntu 16.04\n",
    "    - CPU: Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
    "    - RAM: 64GB \n",
    "    - GPU: NVIDIA Tesla K80\n",
    "- Python\n",
    "    - Python 3.7\n",
    "    - PyTorch 1.3\n",
    "\n",
    "## 文書分類ハンズオン\n",
    "\n",
    "### 本章で扱う自然言語処理ツールの解説\n",
    "\n",
    "#### Transformers\n",
    "\n",
    "Transformersで用いることのできるモデルのリストはHugging Faceのホームページ (https://huggingface.co/models) にて公開されています。\n",
    "\n",
    "-  `bert-base-japanese`:\n",
    "-  `bert-base-japanese-whole-word-masking`\n",
    "-  `bert-base-japanese-char`\n",
    "-  `bert-base-japanese-char-whole-word-masking`\n",
    "\n",
    "Transformersは、FaceBookが開発しているPyTorchおよび、GoogleのTensorFlowのバージョン2.0以降に対応しています。ここではPyTorchを用いることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境によってインストールコマンドが異なります。https://pytorch.org/get-started/を参照してください。\n",
    "# 2019年12月現在、NVIDIAのGPUを搭載したLinuxマシンにAnacondaでPyTorchをインストールするコマンドは以下の通りです。\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# LinuxでかつGPUがない場合は !conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "便利なtorchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install torchtext -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (4.41.0)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (1.10.45)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: click in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.45 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (1.13.45)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bert-base-japanese*` は形態素解析のライブラリとして内部でMeCabを用いているので、`mecab-python3` もインストールしておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、以降で補助的に利用するライブラリもインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: seaborn in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.9.0)\n",
      "Collecting mojimoji\n",
      "  Downloading https://files.pythonhosted.org/packages/10/2d/f5d58e74af1c1b4eeea66ecc14f35ae8f275f39bc7158ba51a6e8a86dfdf/mojimoji-0.0.9.post0.tar.gz\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (1.17.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from seaborn) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (42.0.2.post20191203)\n",
      "Building wheels for collected packages: mojimoji\n",
      "  Building wheel for mojimoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mojimoji: filename=mojimoji-0.0.9-cp37-cp37m-linux_x86_64.whl size=116391 sha256=c849771a8fb83d62824d13e869c1491f75990b1459b63cc0b5106e40c61bf63c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/67/f0/6e/03e5c5017afc8230e19abeacad57189138207fea2f5dd71880\n",
      "Successfully built mojimoji\n",
      "Installing collected packages: mojimoji\n",
      "Successfully installed mojimoji-0.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn seaborn mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn\n",
    "- mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTを用いて日本語の文章を分類する手順はおおまかに書くと以下のようになります。\n",
    "\n",
    "1. aaa\n",
    "2. aaa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['いつも',\n",
       " 'プレゼンテーション',\n",
       " 'の',\n",
       " '撮影',\n",
       " 'に',\n",
       " '無',\n",
       " '##音',\n",
       " 'カメラ',\n",
       " '##アプリ',\n",
       " 'を',\n",
       " 'ご',\n",
       " '利用',\n",
       " 'いただ',\n",
       " '##き',\n",
       " 'ありがとう',\n",
       " 'ござい',\n",
       " 'ます',\n",
       " '。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "tokenizer.tokenize('いつもプレゼンテーションの撮影に無音カメラアプリをご利用いただきありがとうございます。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "#### livedoor ニュースコーパス\n",
    "\n",
    "今回は日本語における自然言語処理の試験用データセットとしてしばしば用いられる「livedoor ニュースコーパス」を用います。\n",
    "\n",
    "livedoorニュースはもともと株式会社ライブドアが運営するニュースサイトでしたが、株式会社ライブドアが旧ハンゲームジャパン株式会社であるNHN Japan株式会社に買収され、現在はNHN Japanが社名変更したLINE株式会社により運営されています。livedoorニュースの記事の一部には「クリエイティブ・コモンズライセンス『表示 – 改変禁止』」が適用されており、営利目的を含めて再配布可能となっています。該当するニュース記事を2012年9月上旬に株式会社ロンウイットが収集し、HTMLタグの除去などクリーニングを施した状態で公開しているのが「livedoor ニュースコーパス」です。\n",
    "\n",
    "livedoor ニュースコーパスは以下のリンクよりダウンロード可能です。\n",
    "\n",
    "https://www.rondhuit.com/download.html#ldcc\n",
    "\n",
    "オープンソースの全文検索システムApache Solrで扱いやすいようXML形式でニュースが格納されている `livedoor-news-data.tar.gz` と、シンプルに各々のニュースをテキストファイルとして扱っている `ldcc-20140209.tar.gz` が公開されています。\n",
    "\n",
    "今回は後者の `ldcc-20140209.tar.gz` をダウンロードしてください。`tar xzvf ldcc-20140209.tar.gz` などにより解凍すると `text` という名前のディレクトリが出てきます。以下のPythonスクリプトを実行するとコーパスのダウンロードと圧縮ファイルの解凍が行われ、カレントディレクトリに `text` ディレクトリが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# dataディレクトリの作成\n",
    "#os.makedirs('data', exist_ok=True)\n",
    "\n",
    "url = 'https://www.rondhuit.com/download/ldcc-20140209.tar.gz'\n",
    "file_name = 'ldcc-20140209.tar.gz'\n",
    "\n",
    "# dataディレクトリへのlivedoor ニュースコーパスのダウンロードと解凍\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    # tar.gzファイルを読み込み\n",
    "    with tarfile.open(file_name) as tar:\n",
    "        tar.extractall()\n",
    "    # tar.gzファイルを消去\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` ディレクトリの中身の構造は以下の通りです。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "├── it-life-hack\n",
    "├── kaden-channel\n",
    "├── livedoor-homme\n",
    "├── movie-enter\n",
    "├── peachy\n",
    "├── smax\n",
    "├── sports-watch\n",
    "└── topic-news\n",
    "```\n",
    "\n",
    "`dokujo-tsushin` から `topic-news` はディレクトリであり、それぞれにニュース記事のテキストが格納されています。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "│   ├── LICENSE.txt\n",
    "│   ├── dokujo-tsushin-4778030.txt\n",
    "│   ├── dokujo-tsushin-4778031.txt\n",
    "│   ├── dokujo-tsushin-4782522.txt\n",
    "...（以下略）\n",
    "```\n",
    "\n",
    "ニュース提供元は以下の9つです。記事の本文だけを見て、その記事がどのカテゴリに属しているのか（独女通信のニュースなのか、ITライフハックのニュースなのか、など）を判別する文書分類モデルを作成するのが本章の目的です。\n",
    "\n",
    "- 独女通信 (http://news.livedoor.com/category/vender/90/)\n",
    "- ITライフハック (http://news.livedoor.com/category/vender/223/)\n",
    "- 家電チャンネル (http://news.livedoor.com/category/vender/kadench/)\n",
    "- livedoor HOMME (http://news.livedoor.com/category/vender/homme/)\n",
    "- MOVIE ENTER (http://news.livedoor.com/category/vender/movie_enter/)\n",
    "- Peachy (http://news.livedoor.com/category/vender/ldgirls/)\n",
    "- エスマックス (http://news.livedoor.com/category/vender/smax/)\n",
    "- Sports Watch (http://news.livedoor.com/category/vender/208/)\n",
    "- トピックニュース (http://news.livedoor.com/category/vender/news/)\n",
    "\n",
    "ちなみに、上記サービスのうちいくつかはドメインが変わっていたり終了しているので一部リンクが切れています。それぞれの記事ファイル（dokujo-tsushin-4778030.txtなど）は以下のフォーマットで構成されています。\n",
    "\n",
    "- １行目: 記事のURL\n",
    "- ２行目: 記事の日付\n",
    "- ３行目: 記事のタイトル\n",
    "- ４行目以降： 記事の本文\n",
    "\n",
    "このままでは少し扱いづらいのでひとつのtsv (tab-separated values) にまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]\n",
    "index = ['url', 'datetime', 'title', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== processing dokujo-tsushin =====\n",
      "===== processing it-life-hack =====\n",
      "===== processing kaden-channel =====\n",
      "===== processing livedoor-homme =====\n",
      "===== processing movie-enter =====\n",
      "===== processing peachy =====\n",
      "===== processing smax =====\n",
      "===== processing sports-watch =====\n",
      "===== processing topic-news =====\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 空のPandasのDataFrameを準備\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# 各サービスのディレクトリでループ\n",
    "for service in services:\n",
    "    print('===== processing {} ====='.format(service))\n",
    "    # ニュース記事をすべて指定\n",
    "    # パスの例は './text/dokujo-tsushin/dokujo-tsushin-4778030.txt'\n",
    "    # LICENSE.txt は除外\n",
    "    wild_card = os.path.join('text', service, service + '*.txt')\n",
    "    file_paths = glob.glob(wild_card)\n",
    "    # 各ニュース記事のファイルパスでループ\n",
    "    for file_path in file_paths:\n",
    "        # ファイルを開いて一行ずつ読み込む\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # tsv のカラムを辞書型で用意\n",
    "            series_dict = {'service': service}\n",
    "            for num, line in enumerate(lines):\n",
    "                # 改行を削除\n",
    "                line = line.replace('\\n', '')\n",
    "                # 0, 1, 2行目はそれぞれURL, 日付, 記事タイトルに相当\n",
    "                if num < len(index):\n",
    "                    series_dict[index[num]] = line\n",
    "                # 3行目以降は本文\n",
    "                else:\n",
    "                    series_dict['body'] += line\n",
    "            # PandasのSeriesを作成し、DataFrameに追加していく\n",
    "            s = pd.Series(series_dict)\n",
    "            df = df.append(s, ignore_index=True)\n",
    "print('done')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した `DataFrame` の最初の5行と最後の5行だけ抜き出して表示してみましょう。\n",
    "それぞれの行がひとつのニュース記事に対応していることより、0行から7366行の計7367個のニュース記事があることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5934284/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>多くの女性が悩む「お腹の張り」。ファッション誌をめくる度に「モデルさんは細くていいなあ…」...</td>\n",
       "      <td>2010-06-25T14:00:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>まるで妊婦！？　モデルの7割が悩む「ポッコリお腹」</td>\n",
       "      <td>http://news.livedoor.com/article/detail/4848785/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>実在した武士の家計簿を元に制作された映画「武士の家計簿」。家計簿をつけ収入収支を管理し、誠実...</td>\n",
       "      <td>2011-01-04T14:00:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>つける？ つけない？ 独女の家計簿</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5247353/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>早いもので、もうすぐ季節は夏。今年は東日本を中心に、ビジネスシーンでのクールビズを例年以上に...</td>\n",
       "      <td>2011-06-22T12:30:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>夏に多発！下着チラみせ独女はアリかナシか？</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5653189/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>女に必要なものは何か。一寸先は真っ暗闇の、生きるというより、生き抜かなくてはいけないこのご時...</td>\n",
       "      <td>2012-01-24T16:09:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>東京23区女ひとり風呂 vol.04「文京区・銭湯後はこの一杯！」Presented by ...</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6218046/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>今年のベストジーニスト一般選出部門に相葉雅紀、黒木メイサが選出された。その選出が“5年ぶりの...</td>\n",
       "      <td>2011-10-05T18:12:00+0900</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>毎年話題になるベストジーニスト賞の偏り</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5914835/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7363</th>\n",
       "      <td>25日、TBSは福島のドキュメンタリー映画を制作する18歳の米国人青年の活動を報じ、ネット掲...</td>\n",
       "      <td>2012-03-26T15:38:00+0900</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>米国人制作の福島の映画「ニュー・ヒバクシャ」に戸惑いの声</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6403803/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>28日発売の「週刊文春」（7月5日号）では、「原一億円恐喝事件で『中畑清DeNA監督が元暴力...</td>\n",
       "      <td>2012-06-28T18:20:00+0900</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>中畑監督の“暴力団員仲介”報道、ネットでも疑問の声続々</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6703537/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7365</th>\n",
       "      <td>4日、Web版「週刊現代」が掲載した記事「民主も自民もついでに財界もこうしてぶっ潰す　橋下徹...</td>\n",
       "      <td>2012-07-04T13:30:00+0900</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>ミキハウスグループ社長が橋下大阪市長を公然批判。ネット上でも話題に</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6723717/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7366</th>\n",
       "      <td>20日、日本の原子力基本法に「安全保障」条項が追加されたが、韓国では「日本が核武装を企んでい...</td>\n",
       "      <td>2012-06-21T20:32:00+0900</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6681547/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1     　多くの女性が悩む「お腹の張り」。ファッション誌をめくる度に「モデルさんは細くていいなあ…」...   \n",
       "2     実在した武士の家計簿を元に制作された映画「武士の家計簿」。家計簿をつけ収入収支を管理し、誠実...   \n",
       "3     早いもので、もうすぐ季節は夏。今年は東日本を中心に、ビジネスシーンでのクールビズを例年以上に...   \n",
       "4     女に必要なものは何か。一寸先は真っ暗闇の、生きるというより、生き抜かなくてはいけないこのご時...   \n",
       "7362  今年のベストジーニスト一般選出部門に相葉雅紀、黒木メイサが選出された。その選出が“5年ぶりの...   \n",
       "7363  25日、TBSは福島のドキュメンタリー映画を制作する18歳の米国人青年の活動を報じ、ネット掲...   \n",
       "7364  28日発売の「週刊文春」（7月5日号）では、「原一億円恐喝事件で『中畑清DeNA監督が元暴力...   \n",
       "7365  4日、Web版「週刊現代」が掲載した記事「民主も自民もついでに財界もこうしてぶっ潰す　橋下徹...   \n",
       "7366  20日、日本の原子力基本法に「安全保障」条項が追加されたが、韓国では「日本が核武装を企んでい...   \n",
       "\n",
       "                      datetime         service  \\\n",
       "0     2011-10-13T15:28:00+0900  dokujo-tsushin   \n",
       "1     2010-06-25T14:00:00+0900  dokujo-tsushin   \n",
       "2     2011-01-04T14:00:00+0900  dokujo-tsushin   \n",
       "3     2011-06-22T12:30:00+0900  dokujo-tsushin   \n",
       "4     2012-01-24T16:09:00+0900  dokujo-tsushin   \n",
       "7362  2011-10-05T18:12:00+0900      topic-news   \n",
       "7363  2012-03-26T15:38:00+0900      topic-news   \n",
       "7364  2012-06-28T18:20:00+0900      topic-news   \n",
       "7365  2012-07-04T13:30:00+0900      topic-news   \n",
       "7366  2012-06-21T20:32:00+0900      topic-news   \n",
       "\n",
       "                                                  title  \\\n",
       "0                      「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音   \n",
       "1                             まるで妊婦！？　モデルの7割が悩む「ポッコリお腹」   \n",
       "2                                     つける？ つけない？ 独女の家計簿   \n",
       "3                                 夏に多発！下着チラみせ独女はアリかナシか？   \n",
       "4     東京23区女ひとり風呂 vol.04「文京区・銭湯後はこの一杯！」Presented by ...   \n",
       "7362                                毎年話題になるベストジーニスト賞の偏り   \n",
       "7363                       米国人制作の福島の映画「ニュー・ヒバクシャ」に戸惑いの声   \n",
       "7364                        中畑監督の“暴力団員仲介”報道、ネットでも疑問の声続々   \n",
       "7365                  ミキハウスグループ社長が橋下大阪市長を公然批判。ネット上でも話題に   \n",
       "7366           原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声   \n",
       "\n",
       "                                                   url  \n",
       "0     http://news.livedoor.com/article/detail/5934284/  \n",
       "1     http://news.livedoor.com/article/detail/4848785/  \n",
       "2     http://news.livedoor.com/article/detail/5247353/  \n",
       "3     http://news.livedoor.com/article/detail/5653189/  \n",
       "4     http://news.livedoor.com/article/detail/6218046/  \n",
       "7362  http://news.livedoor.com/article/detail/5914835/  \n",
       "7363  http://news.livedoor.com/article/detail/6403803/  \n",
       "7364  http://news.livedoor.com/article/detail/6703537/  \n",
       "7365  http://news.livedoor.com/article/detail/6723717/  \n",
       "7366  http://news.livedoor.com/article/detail/6681547/  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.head(), df.tail()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports-watch      900\n",
       "smax              870\n",
       "it-life-hack      870\n",
       "dokujo-tsushin    870\n",
       "movie-enter       870\n",
       "kaden-channel     864\n",
       "peachy            842\n",
       "topic-news        770\n",
       "livedoor-homme    511\n",
       "Name: service, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f60405aca90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df['service'].value_counts()).plot(kind='bar', rot=45, ylim=(0, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5934284/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>多くの女性が悩む「お腹の張り」。ファッション誌をめくる度に「モデルさんは細くていいなあ…」...</td>\n",
       "      <td>2010-06-25T14:00:00+0900</td>\n",
       "      <td>0</td>\n",
       "      <td>まるで妊婦！？　モデルの7割が悩む「ポッコリお腹」</td>\n",
       "      <td>http://news.livedoor.com/article/detail/4848785/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>実在した武士の家計簿を元に制作された映画「武士の家計簿」。家計簿をつけ収入収支を管理し、誠実...</td>\n",
       "      <td>2011-01-04T14:00:00+0900</td>\n",
       "      <td>0</td>\n",
       "      <td>つける？ つけない？ 独女の家計簿</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5247353/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>早いもので、もうすぐ季節は夏。今年は東日本を中心に、ビジネスシーンでのクールビズを例年以上に...</td>\n",
       "      <td>2011-06-22T12:30:00+0900</td>\n",
       "      <td>0</td>\n",
       "      <td>夏に多発！下着チラみせ独女はアリかナシか？</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5653189/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>女に必要なものは何か。一寸先は真っ暗闇の、生きるというより、生き抜かなくてはいけないこのご時...</td>\n",
       "      <td>2012-01-24T16:09:00+0900</td>\n",
       "      <td>0</td>\n",
       "      <td>東京23区女ひとり風呂 vol.04「文京区・銭湯後はこの一杯！」Presented by ...</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6218046/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1  　多くの女性が悩む「お腹の張り」。ファッション誌をめくる度に「モデルさんは細くていいなあ…」...   \n",
       "2  実在した武士の家計簿を元に制作された映画「武士の家計簿」。家計簿をつけ収入収支を管理し、誠実...   \n",
       "3  早いもので、もうすぐ季節は夏。今年は東日本を中心に、ビジネスシーンでのクールビズを例年以上に...   \n",
       "4  女に必要なものは何か。一寸先は真っ暗闇の、生きるというより、生き抜かなくてはいけないこのご時...   \n",
       "\n",
       "                   datetime  service  \\\n",
       "0  2011-10-13T15:28:00+0900        0   \n",
       "1  2010-06-25T14:00:00+0900        0   \n",
       "2  2011-01-04T14:00:00+0900        0   \n",
       "3  2011-06-22T12:30:00+0900        0   \n",
       "4  2012-01-24T16:09:00+0900        0   \n",
       "\n",
       "                                               title  \\\n",
       "0                   「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音   \n",
       "1                          まるで妊婦！？　モデルの7割が悩む「ポッコリお腹」   \n",
       "2                                  つける？ つけない？ 独女の家計簿   \n",
       "3                              夏に多発！下着チラみせ独女はアリかナシか？   \n",
       "4  東京23区女ひとり風呂 vol.04「文京区・銭湯後はこの一杯！」Presented by ...   \n",
       "\n",
       "                                                url  \n",
       "0  http://news.livedoor.com/article/detail/5934284/  \n",
       "1  http://news.livedoor.com/article/detail/4848785/  \n",
       "2  http://news.livedoor.com/article/detail/5247353/  \n",
       "3  http://news.livedoor.com/article/detail/5653189/  \n",
       "4  http://news.livedoor.com/article/detail/6218046/  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['service'] = le.fit_transform(df.service.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df[['body', 'service']]\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` をCSV (Comma-Separated Value) やTSV (Tab-Separated Value) で保存するには `pandas.DataFrame.to_csv` メソッドを呼び出します。ひとつ目の引数 `path_or_buf` には保存先のファイルパス（もしくはファイルオブジェクト）を指定し、ふたつ目の引数 `sep` には列のセパレーターを指定します。デフォルトでは `sep=','` となっており、セパレーターはカンマ、つまり `DataFrame` はCSVで保存されます。自然言語処理を行う場合、データ内にカンマが含まれていることがあるのでしばしばセパレーターとしてはタブ (`\\t`) が用いられます。ここでは `DataFrame` をTSVの形式で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv', sep='\\t', index=False)\n",
    "val_df.to_csv('val.tsv', sep='\\t', index=False)\n",
    "test_df.to_csv('test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ラベリング\n",
    "\n",
    "### 前処理\n",
    "\n",
    "\n",
    "\n",
    "#### 形態素解析\n",
    "#### ストップワード除去\n",
    "\n",
    "### 文書分類モデル\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\ndf = pd.read_csv('news.tsv', sep='\\t', index_col=0)\\ndf = df[['body', 'service']]\\ndf.head()\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv('news.tsv', sep='\\t', index_col=0)\n",
    "df = df[['body', 'service']]\n",
    "df.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import LabelEncoder\\nle = LabelEncoder()\\ndf['service'] = le.fit_transform(df.service.values)\\ndf.head()\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['service'] = le.fit_transform(df.service.values)\n",
    "df.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>先週前半は、嵐の前の静けさといった感じで、かなり平穏でした。それもあってニュースのネタ探しに...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>23日、千葉県総合スポーツセンター陸上競技場では、国際千葉駅伝が行われた。レースは、ケニアが...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>ゼロから始めるスマートフォン ZTEは19日（現地時間）、現在シンガポールで開催されている展...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>ドコモは2012年3月5日 、「ドコモwebメール」を2012年8月27日午前11時をもって...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>現在、全米で大ヒット継続中で、2年連続“最も好きな犯罪ドラマ”にも選ばれている人気海外ドラ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  service\n",
       "1536  先週前半は、嵐の前の静けさといった感じで、かなり平穏でした。それもあってニュースのネタ探しに...        1\n",
       "6175  23日、千葉県総合スポーツセンター陸上競技場では、国際千葉駅伝が行われた。レースは、ケニアが...        7\n",
       "5130  ゼロから始めるスマートフォン ZTEは19日（現地時間）、現在シンガポールで開催されている展...        6\n",
       "1123  ドコモは2012年3月5日 、「ドコモwebメール」を2012年8月27日午前11時をもって...        1\n",
       "3450  　現在、全米で大ヒット継続中で、2年連続“最も好きな犯罪ドラマ”にも選ばれている人気海外ドラ...        4"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>省エネ効果があり、従来の蛍光灯や電球と違って長期間使用が可能で、しかも明るいLEDライト。今...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>ＳＦ小説の巨匠ロバート・Ａ・ハインラインの傑作『宇宙の戦士』を映画化し、巨大昆虫と戦う兵士...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>昨年12月、大阪府立体育会館で開催された、ボクシング・WBA世界ダブルタイトルマッチにおいて...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>20日、ハロープロジェクトに所属するアイドルグループ「スマイレージ」のスタッフが管理するツイ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>先日ひと騒動あった不審なAndroidアプリの件、「ヘンなアプリに要注意！ データぶっこ抜き...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  service\n",
       "2513  省エネ効果があり、従来の蛍光灯や電球と違って長期間使用が可能で、しかも明るいLEDライト。今...        2\n",
       "3374  　ＳＦ小説の巨匠ロバート・Ａ・ハインラインの傑作『宇宙の戦士』を映画化し、巨大昆虫と戦う兵士...        4\n",
       "6048  昨年12月、大阪府立体育会館で開催された、ボクシング・WBA世界ダブルタイトルマッチにおいて...        7\n",
       "6894  20日、ハロープロジェクトに所属するアイドルグループ「スマイレージ」のスタッフが管理するツイ...        8\n",
       "1485  先日ひと騒動あった不審なAndroidアプリの件、「ヘンなアプリに要注意！ データぶっこ抜き...        1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "net = BertForSequenceClassification.from_pretrained('bert-base-japanese-whole-word-masking', num_labels=9)\n",
    "net.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このニューラルネットワークの構造をnetron (https://github.com/lutzroeder/netron) というツールを用いて可視化すると次のようになります。\n",
    "<img src=\"../figures/bert_classifier_netron.png\" alt=\"bert_classifier_netron\" width=\"150\">\n",
    "BERTモデルの構造が `BertModel` に押し込められているため、やけにシンプルに見えますが、ここではあまり深く考えないようにします。\n",
    "\n",
    "PyTorchを用いてディープラーニングを実装する際には"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "\n",
    "import re\n",
    "import mojimoji\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "        # 半角、全角の変換\n",
    "        text = mojimoji.han_to_zen(text)\n",
    "        # 改行、半角スペース、全角スペースを削除\n",
    "        text = re.sub('\\r', '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('　', '', text)\n",
    "        text = re.sub(' ', '', text)\n",
    "        # 数字文字の一律「0」化\n",
    "        text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
    "        return tokenizer.tokenize(text)\n",
    "    \n",
    "TEXT = Field(\n",
    "    sequential=True,  \n",
    "    tokenize=tokenizer_with_preprocessing, \n",
    "    use_vocab=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    batch_first=True,\n",
    "    fix_length=512,\n",
    "    init_token='[CLS]',\n",
    "    eos_token='[SEP]',\n",
    "    pad_token='[PAD]',\n",
    "    unk_token='[UNK]'\n",
    ")\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "train, val, test = TabularDataset.splits(path='.', train='train.tsv', validation='val.tsv', test='test.tsv', format='tsv', fields=[('body', TEXT), ('service', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=1)\n",
    "TEXT.vocab.stoi = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Iterator\n",
    "batch_size = 8\n",
    "train_iter, val_iter, test_iter = Iterator.splits((train, val, test), batch_size=batch_size, device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_dict = {'train': train_iter, 'val': val_iter, 'test': test_iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnet.to('cuda')\\nbatch = next(iter(train_iter))\\ninputs = batch.body[0]\\nlabels = batch.service\\nloss, logit = net(inputs, labels=labels)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "net.to('cuda')\n",
    "batch = next(iter(train_iter))\n",
    "inputs = batch.body[0]\n",
    "labels = batch.service\n",
    "loss, logit = net(inputs, labels=labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.classifier.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "    {'params': net.classifier.parameters(), 'lr': 5e-5}\n",
    "], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, iterator_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.\n",
    "            epoch_corrects = 0\n",
    "            iteration = 1\n",
    "            \n",
    "            for batch in iterator_dict[phase]:\n",
    "                inputs = batch.body[0]\n",
    "                labels = batch.service\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    loss, logit = net(input_ids=inputs, labels=labels)\n",
    "                    #print(loss, logit)\n",
    "                    _, preds = torch.max(logit, 1)\n",
    "                    #predictions.append(preds.cpu().numpy())\n",
    "                    #ground_truths.append(labels.data.cpu().numpy())\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            acc = (torch.sum(preds == labels.data)).double() / batch_size\n",
    "                            print('iteration {} || Loss: {:.4f} || acc {}'.format(\n",
    "                                iteration, loss.item(), acc.item()))\n",
    "                    iteration += 1\n",
    "                    \n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = epoch_loss / len(iterator_dict[phase].dataset)\n",
    "        epoch_acc = epoch_corrects.double() / len(iterator_dict[phase].dataset)\n",
    "        \n",
    "        print('Epoch {}/{} | {} | Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            epoch+1, num_epochs, phase, epoch_loss, epoch_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10 || Loss: 1.5891 || acc 0.625\n",
      "iteration 20 || Loss: 1.5974 || acc 0.75\n",
      "iteration 30 || Loss: 1.2715 || acc 0.625\n",
      "iteration 40 || Loss: 1.5708 || acc 0.5\n",
      "iteration 50 || Loss: 0.8519 || acc 0.875\n",
      "iteration 60 || Loss: 1.2821 || acc 0.375\n",
      "iteration 70 || Loss: 0.6059 || acc 1.0\n",
      "iteration 80 || Loss: 0.5998 || acc 1.0\n",
      "iteration 90 || Loss: 0.6772 || acc 0.75\n",
      "iteration 100 || Loss: 1.0835 || acc 0.625\n",
      "iteration 110 || Loss: 0.6970 || acc 0.75\n",
      "iteration 120 || Loss: 1.1107 || acc 0.625\n",
      "iteration 130 || Loss: 0.6839 || acc 0.75\n",
      "iteration 140 || Loss: 0.8002 || acc 0.75\n",
      "iteration 150 || Loss: 0.5608 || acc 0.75\n",
      "iteration 160 || Loss: 1.4367 || acc 0.5\n",
      "iteration 170 || Loss: 0.6620 || acc 0.75\n",
      "iteration 180 || Loss: 0.1703 || acc 1.0\n",
      "iteration 190 || Loss: 0.5071 || acc 0.875\n",
      "iteration 200 || Loss: 0.8674 || acc 0.625\n",
      "iteration 210 || Loss: 0.5108 || acc 0.875\n",
      "iteration 220 || Loss: 0.5729 || acc 0.875\n",
      "iteration 230 || Loss: 0.4816 || acc 0.875\n",
      "iteration 240 || Loss: 0.6490 || acc 0.875\n",
      "iteration 250 || Loss: 1.0121 || acc 0.75\n",
      "iteration 260 || Loss: 0.7322 || acc 0.875\n",
      "iteration 270 || Loss: 0.3705 || acc 0.875\n",
      "iteration 280 || Loss: 0.5658 || acc 0.875\n",
      "iteration 290 || Loss: 0.7428 || acc 0.625\n",
      "iteration 300 || Loss: 0.3046 || acc 1.0\n",
      "iteration 310 || Loss: 0.5171 || acc 0.75\n",
      "iteration 320 || Loss: 0.5932 || acc 0.875\n",
      "iteration 330 || Loss: 0.5327 || acc 0.875\n",
      "iteration 340 || Loss: 0.2622 || acc 1.0\n",
      "iteration 350 || Loss: 0.3007 || acc 0.875\n",
      "iteration 360 || Loss: 0.3536 || acc 0.75\n",
      "iteration 370 || Loss: 0.7962 || acc 0.75\n",
      "iteration 380 || Loss: 0.7173 || acc 0.75\n",
      "iteration 390 || Loss: 0.1885 || acc 1.0\n",
      "iteration 400 || Loss: 0.6217 || acc 0.875\n",
      "iteration 410 || Loss: 0.6740 || acc 0.875\n",
      "iteration 420 || Loss: 0.4056 || acc 0.875\n",
      "iteration 430 || Loss: 0.6902 || acc 0.625\n",
      "iteration 440 || Loss: 0.1920 || acc 1.0\n",
      "iteration 450 || Loss: 0.4077 || acc 0.875\n",
      "iteration 460 || Loss: 0.8450 || acc 0.875\n",
      "iteration 470 || Loss: 0.3757 || acc 0.875\n",
      "iteration 480 || Loss: 0.4408 || acc 0.75\n",
      "iteration 490 || Loss: 0.5186 || acc 0.875\n",
      "iteration 500 || Loss: 0.2332 || acc 1.0\n",
      "iteration 510 || Loss: 0.5038 || acc 0.875\n",
      "iteration 520 || Loss: 0.1663 || acc 1.0\n",
      "iteration 530 || Loss: 0.3707 || acc 0.875\n",
      "iteration 540 || Loss: 0.2564 || acc 0.875\n",
      "iteration 550 || Loss: 0.2183 || acc 1.0\n",
      "iteration 560 || Loss: 0.2020 || acc 1.0\n",
      "iteration 570 || Loss: 0.0793 || acc 1.0\n",
      "iteration 580 || Loss: 0.3869 || acc 0.875\n",
      "iteration 590 || Loss: 0.4610 || acc 0.875\n",
      "iteration 600 || Loss: 0.4602 || acc 0.875\n",
      "iteration 610 || Loss: 0.5223 || acc 0.875\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'service'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2d1666ffe01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-e655fc09ecaf>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, iterator_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 arr = [numericalization_func(x) if isinstance(x, six.string_types)\n\u001b[0;32m--> 355\u001b[0;31m                        else x for x in arr]\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 arr = [numericalization_func(x) if isinstance(x, six.string_types)\n\u001b[0;32m--> 355\u001b[0;31m                        else x for x in arr]\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'service'"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "net_trained = train_model(net, iterator_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価と比較\n",
    "\n",
    "### モデルのデプロイ\n",
    "\n",
    "## まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
