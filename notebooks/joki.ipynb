{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章 タイトル未定\n",
    "\n",
    "本章では文書分類モデルの作成を通じて自然言語処理で用いられる数々のPythonツールの利用方法を学びます。\n",
    "\n",
    "なお、動作確認は以下の環境で行いました。\n",
    "\n",
    "- Machine (AWS EC2 p2.xlargeインスタンス)\n",
    "    - OS: Ubuntu 16.04\n",
    "    - CPU: Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
    "    - RAM: 64GB \n",
    "    - GPU: NVIDIA Tesla K80\n",
    "- Python\n",
    "    - python: 3.7.5\n",
    "    - mecab-python3: 0.996.2\n",
    "    - torch (PyTorch): 1.3.1\n",
    "    - torchtext: 0.4.0\n",
    "    - transformers 2.3.0\n",
    "    - spaCy 2.2.3\n",
    "    - cupy 7.0.0\n",
    "    \n",
    "## 3.1 機械学習モデル開発のワークフローと本章で扱う内容\n",
    "\n",
    "文書分類のモデルは基本的に**教師あり学習**の枠組みで訓練します。つまり、図のようにテキストとラベルのペアで訓練データを用意します。例えばニュース記事があるとして、その記事はスポーツニュースなのか、芸能ニュースなのか、政治ニュースなのかを記事内の文章から分類したいとします。このときニュース記事の文章と、分類すべきカテゴリーの名前をペアとして扱います。\n",
    "\n",
    "![training.svg](../figures/training.svg)\n",
    "<center>図出典: https://spacy.io/usage/training</center>\n",
    "\n",
    "1. 訓練用のデータセットを用意する\n",
    "2. 分類に用いる機械学習モデルを準備する\n",
    "3. モデルに訓練データのテキストを入力して予測値を得る\n",
    "4. モデルの予測と真のラベルを比較する\n",
    "5. 誤差を減らすようなモデルのパラメーター (重み) の更新値 (gradient) を計算する\n",
    "6. モデルのパラメーターを更新する\n",
    "7. 3から6を繰り返す\n",
    "\n",
    "## 3.2 文書分類ハンズオン\n",
    "\n",
    "### 3.2.1 本章で扱う自然言語処理ツールの解説\n",
    "\n",
    "#### 3.2.1.1 spaCy\n",
    "\n",
    "spaCy (https://spacy.io/) とはExplosion AIにより開発されている自然言語処理用のライブラリです。spaCyには事前学習済みの統計モデルと単語ベクトルが付属しており、50以上の言語の形態素解析（トークン化）がサポートされています。また、品詞タグ付け、依存関係解析、固有表現抽出、およびテキスト分類のための単語バッグや簡単な畳み込みニューラルネットワークモデルも備えています。MITライセンスの下でリリースされた商用のオープンソースソフトウェアです。\n",
    "\n",
    "spaCyのドキュメンテーション (https://spacy.io/usage/) に従ってインストールしてみましょう。環境によってインストールコマンドが異なるので適宜ドキュメンテーションを参考にしてください。ここではGPU付きのオプションでインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy[cuda]\n",
    "# pip install -U spacy  # GPUを利用しない場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCyと同時に、Explosion AIにより開発されているThinc (https://github.com/explosion/thinc) という機械学習ライブラリや、Preferred NetworksのCUDA対応のNumPy互換行列計算ライブラリであるCuPy (https://cupy.chainer.org/) などがインストールされます。\n",
    "\n",
    "日本語の形態素解析ツールのMeCab (http://taku910.github.io/mecab/) もインストールしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分かち書きのテストをしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank('ja')\n",
    "for word in nlp('すもももももももものうち'):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく単語ごとに分割してくれていますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Transformers\n",
    "\n",
    "Transformersはtransformerベースの汎用アーキテクチャ （BERT、GPT-2、RoBERTa、XLM、DistilBert、XLNet、CTRL、...） を利用するためのオープンソースのシンプルなAPIを提供しています。開発はHugging Faceにより行われており、100以上の言語に対応した事前学習済みモデルが公開されています。ディープラーニングフレームワークとしてはGoogleのTensorFlow 2.0およびFaceBookが開発しているPyTorchに対応しています。ここではPyTorchを用いることにします。\n",
    "\n",
    "Transformersで用いることのできるモデルのリストはHugging Faceのホームページ (https://huggingface.co/models) にて公開されています。日本語用BERTモデルとしては、執筆時点 (2019年12月) では東北大学 乾・鈴木研究室が公開している以下の4つのモデルを利用可能です。\n",
    "\n",
    "-  `bert-base-japanese`:\n",
    "-  `bert-base-japanese-whole-word-masking`\n",
    "-  `bert-base-japanese-char`\n",
    "-  `bert-base-japanese-char-whole-word-masking`\n",
    "\n",
    "BERTには大きく分けて `BERT-Base` (12-layer, 768-hidden, 12-heads, 110M parameters) と `BERT-Large` (24-layer, 1024-hidden, 16-heads, 340M parameters) のふたつのアーキテクチャーがあります。上記のモデルは `BERT-Base` を日本語のWikipediaのデータを用いて訓練したものです。`bert-base-japanese` はMeCabとWordPieceと呼ばれる手法を用いてテキストの分かち書きを行った後に訓練されたものであり、`bert-base-japanese-char` ではテキストを文字ごとに分割しています。\n",
    "\n",
    "BERTの訓練時に行うタスクのひとつに、文章内のトークンをマスクし、そのトークンを予測する、というものがあります。例えば `\"He likes playing the piano.\"` という文章を `\"He likes [MASK] ##ing the piano.\"` という文章に変換し、`[MASK]` に含まれるトークンを予測します。なお、`##` から始まるトークンは接尾辞を表しています。このとき、単語に対応するトークンはまとめてマスクするのが Whole Word Masking と呼ばれる手法です。先ほどの文章を `\"He likes [MASK] [MASK] the piano.\"` のようにマスクして訓練したモデルが `bert-base-japanese-whole-word-masking` および、`bert-base-japanese-char-whole-word-masking` です。\n",
    "\n",
    "さて、transformersをインストールしてみましょう。環境によってインストールコマンドが異なります。https://pytorch.org/get-started/ を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019年12月現在、NVIDIAのGPUを搭載したLinuxマシンにAnacondaでPyTorchをインストールするコマンドは以下の通りです。\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# LinuxでかつGPUがない場合は conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchで自然言語処理を行うときに便利なライブラリであるtorchtextもインストールしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install torchtext -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformersのインストールもpipを用いて簡単に行えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、以降で補助的に利用するライブラリもインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn seaborn mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn\n",
    "- mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformersの `BertJapaneseTokenizer` を用いた日本語文章の分かち書きのテストもしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "tokenizer.tokenize('いつもプレゼンテーションの撮影に無音カメラアプリをご利用いただきありがとうございます。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 データセットの準備\n",
    "#### 3.2.2.1 livedoor ニュースコーパス\n",
    "\n",
    "今回は日本語における自然言語処理の試験用データセットとしてしばしば用いられる「livedoor ニュースコーパス」を用います。\n",
    "\n",
    "livedoorニュースはもともと株式会社ライブドアが運営するニュースサイトでしたが、株式会社ライブドアが旧ハンゲームジャパン株式会社であるNHN Japan株式会社に買収され、現在はNHN Japanが社名変更したLINE株式会社により運営されています。livedoorニュースの記事の一部には「クリエイティブ・コモンズライセンス『表示 – 改変禁止』」が適用されており、営利目的を含めて再配布可能となっています。該当するニュース記事を2012年9月上旬に株式会社ロンウイットが収集し、HTMLタグの除去などクリーニングを施した状態で公開しているのが「livedoor ニュースコーパス」です。\n",
    "\n",
    "livedoor ニュースコーパスは以下のリンクよりダウンロード可能です。\n",
    "\n",
    "https://www.rondhuit.com/download.html#ldcc\n",
    "\n",
    "オープンソースの全文検索システムApache Solrで扱いやすいようXML形式でニュースが格納されている `livedoor-news-data.tar.gz` と、シンプルに各々のニュースをテキストファイルとして扱っている `ldcc-20140209.tar.gz` が公開されています。\n",
    "\n",
    "今回は後者の `ldcc-20140209.tar.gz` をダウンロードしてください。`tar xzvf ldcc-20140209.tar.gz` などにより解凍すると `text` という名前のディレクトリが出てきます。以下のPythonスクリプトを実行するとコーパスのダウンロードと圧縮ファイルの解凍が行われ、カレントディレクトリに `text` ディレクトリが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# dataディレクトリの作成\n",
    "#os.makedirs('data', exist_ok=True)\n",
    "\n",
    "url = 'https://www.rondhuit.com/download/ldcc-20140209.tar.gz'\n",
    "file_name = 'ldcc-20140209.tar.gz'\n",
    "\n",
    "# dataディレクトリへのlivedoor ニュースコーパスのダウンロードと解凍\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    # tar.gzファイルを読み込み\n",
    "    with tarfile.open(file_name) as tar:\n",
    "        tar.extractall()\n",
    "    # tar.gzファイルを消去\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` ディレクトリの中身の構造は以下の通りです。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "├── it-life-hack\n",
    "├── kaden-channel\n",
    "├── livedoor-homme\n",
    "├── movie-enter\n",
    "├── peachy\n",
    "├── smax\n",
    "├── sports-watch\n",
    "└── topic-news\n",
    "```\n",
    "\n",
    "`dokujo-tsushin` から `topic-news` はディレクトリであり、それぞれにニュース記事のテキストが格納されています。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "│   ├── LICENSE.txt\n",
    "│   ├── dokujo-tsushin-4778030.txt\n",
    "│   ├── dokujo-tsushin-4778031.txt\n",
    "│   ├── dokujo-tsushin-4782522.txt\n",
    "...（以下略）\n",
    "```\n",
    "\n",
    "ニュース提供元は以下の9つです。記事の本文だけを見て、その記事がどのカテゴリに属しているのか（独女通信のニュースなのか、ITライフハックのニュースなのか、など）を判別する文書分類モデルを作成するのが本章の目的です。\n",
    "\n",
    "- 独女通信 (http://news.livedoor.com/category/vender/90/)\n",
    "- ITライフハック (http://news.livedoor.com/category/vender/223/)\n",
    "- 家電チャンネル (http://news.livedoor.com/category/vender/kadench/)\n",
    "- livedoor HOMME (http://news.livedoor.com/category/vender/homme/)\n",
    "- MOVIE ENTER (http://news.livedoor.com/category/vender/movie_enter/)\n",
    "- Peachy (http://news.livedoor.com/category/vender/ldgirls/)\n",
    "- エスマックス (http://news.livedoor.com/category/vender/smax/)\n",
    "- Sports Watch (http://news.livedoor.com/category/vender/208/)\n",
    "- トピックニュース (http://news.livedoor.com/category/vender/news/)\n",
    "\n",
    "ちなみに、上記サービスのうちいくつかはドメインが変わっていたり終了しているので一部リンクが切れています。それぞれの記事ファイル（dokujo-tsushin-4778030.txtなど）は以下のフォーマットで構成されています。\n",
    "\n",
    "- １行目: 記事のURL\n",
    "- ２行目: 記事の日付\n",
    "- ３行目: 記事のタイトル\n",
    "- ４行目以降： 記事の本文\n",
    "\n",
    "このままでは少し扱いづらいのでひとつのtsv (tab-separated values) にまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]\n",
    "index = ['url', 'datetime', 'title', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# あまりに短い文章は除く\n",
    "minimum_sentence_length = 32\n",
    "\n",
    "# 空のPandasのDataFrameを準備\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# 各サービスのディレクトリでループ\n",
    "for service in services:\n",
    "    print('===== processing {} ====='.format(service))\n",
    "    # ニュース記事をすべて指定\n",
    "    # パスの例は './text/dokujo-tsushin/dokujo-tsushin-4778030.txt'\n",
    "    # LICENSE.txt は除外\n",
    "    wild_card = os.path.join('text', service, service + '*.txt')\n",
    "    file_paths = glob.glob(wild_card)\n",
    "    # 各ニュース記事のファイルパスでループ\n",
    "    for file_path in file_paths:\n",
    "        # ファイルを開いて一行ずつ読み込む\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # tsv のカラムを辞書型で用意\n",
    "            series_dict = {'service': service}\n",
    "            for num, line in enumerate(lines):\n",
    "                #line = line.replace('\\n', '')  # 改行を削除\n",
    "                # 0, 1, 2行目はそれぞれURL, 日付, 記事タイトルに相当\n",
    "                if num < len(index):\n",
    "                    series_dict[index[num]] = line\n",
    "                # 3行目以降は本文\n",
    "                elif line != '\\n' and line != '':\n",
    "                    series_dict['body'] += line\n",
    "                # lineが空（段落の境目もしくはファイルの末尾）の場合\n",
    "                else:\n",
    "                    if '関連記事' in series_dict['body']:\n",
    "                        pass\n",
    "                    elif '関連リンク' in series_dict['body']:\n",
    "                        pass\n",
    "                    # PandasのSeriesを作成し、DataFrameに追加していく\n",
    "                    elif len(series_dict['body']) > minimum_sentence_length:\n",
    "                        s = pd.Series(series_dict)\n",
    "                        df = df.append(s, ignore_index=True)\n",
    "                    # bodyを初期化\n",
    "                    series_dict['body'] = ''\n",
    "print('done')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した `DataFrame` の最初の5行と最後の5行だけ抜き出して表示してみましょう。\n",
    "それぞれの行がひとつのニュース記事に対応していることより、0行から7366行の計7367個のニュース記事があることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df.head(3), df.tail(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df['service'].value_counts()).plot(kind='bar', rot=45, ylim=(0, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['service'] = le.fit_transform(df.service.values)\n",
    "pd.concat([df.head(3), df.tail(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df[['body', 'service']]\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` をCSV (Comma-Separated Value) やTSV (Tab-Separated Value) で保存するには `pandas.DataFrame.to_csv` メソッドを呼び出します。ひとつ目の引数 `path_or_buf` には保存先のファイルパス（もしくはファイルオブジェクト）を指定し、ふたつ目の引数 `sep` には列のセパレーターを指定します。デフォルトでは `sep=','` となっており、セパレーターはカンマ、つまり `DataFrame` はCSVで保存されます。自然言語処理を行う場合、データ内にカンマが含まれていることがあるのでしばしばセパレーターとしてはタブ (`\\t`) が用いられます。ここでは `DataFrame` をTSVの形式で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv', sep='\\t', index=False)\n",
    "val_df.to_csv('val.tsv', sep='\\t', index=False)\n",
    "test_df.to_csv('test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ラベリング\n",
    "\n",
    "### 前処理\n",
    "\n",
    "\n",
    "\n",
    "#### 形態素解析\n",
    "#### ストップワード除去\n",
    "\n",
    "### 3.2.3 文書分類モデル\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 単語バッグ  (bag-of-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.ja.JapaneseTokenizer at 0x7fddce8f6b10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.blank('ja')\n",
    "nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"https://github.com/megagonlabs/ginza/releases/download/latest/ginza-latest.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#nlp = spacy.load('ja_ginza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('train.tsv', delimiter='\\t')\n",
    "df_val = pd.read_csv('val.tsv', delimiter='\\t')\n",
    "df_test = pd.read_csv('test.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df_train.body\n",
    "val_texts = df_val.body\n",
    "test_texts = df_test.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私の環境ではそれぞれ30秒、4秒、3秒ほどかかりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = list(nlp.pipe(train_texts))\n",
    "val_docs = list(nlp.pipe(val_texts))\n",
    "test_docs = list(nlp.pipe(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        6\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "45299    7\n",
       "45300    1\n",
       "45301    4\n",
       "45302    0\n",
       "45303    6\n",
       "Name: service, Length: 45304, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "奇妙だけど'cats'キーが必要なのだ。\n",
    "nlp.update without required annotation types. Expected top-level keys: ('words', 'tags', 'heads', 'deps', 'entities', 'cats', 'links')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats = [{'cats': {service: service == services[idx] for service in services}}\n",
    "              for idx in df_train.service]\n",
    "val_cats = [{'cats': {service: service == services[idx] for service in services}}\n",
    "            for idx in df_val.service]\n",
    "test_cats = [{'cats': {service: service == services[idx] for service in services}}\n",
    "             for idx in df_test.service]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cats': {'dokujo-tsushin': True,\n",
       "   'it-life-hack': False,\n",
       "   'kaden-channel': False,\n",
       "   'livedoor-homme': False,\n",
       "   'movie-enter': False,\n",
       "   'peachy': False,\n",
       "   'smax': False,\n",
       "   'sports-watch': False,\n",
       "   'topic-news': False}},\n",
       " {'cats': {'dokujo-tsushin': False,\n",
       "   'it-life-hack': True,\n",
       "   'kaden-channel': False,\n",
       "   'livedoor-homme': False,\n",
       "   'movie-enter': False,\n",
       "   'peachy': False,\n",
       "   'smax': False,\n",
       "   'sports-watch': False,\n",
       "   'topic-news': False}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cats[0:2]\n",
    "val_cats[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_docs, train_cats))\n",
    "val_data = list(zip(val_docs, val_cats))\n",
    "test_data = list(zip(test_docs, test_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "＜症状＞　顧客の話の文脈がつかめない、的外れな質問ばかりしている気がする。 ＜効果＞　どこに着目して情報収集すればいいかが\n",
      "{'cats': {'dokujo-tsushin': False, 'it-life-hack': False, 'kaden-channel': False, 'livedoor-homme': True, 'movie-enter': False, 'peachy': False, 'smax': False, 'sports-watch': False, 'topic-news': False}}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0][:40])\n",
    "print(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\", \n",
    "                              config={\"exclusive_classes\": True, \"architecture\": \"bow\"})\n",
    "    nlp.add_pipe(textcat, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add label dokujo-tsushin.\n",
      "Add label it-life-hack.\n",
      "Add label kaden-channel.\n",
      "Add label livedoor-homme.\n",
      "Add label movie-enter.\n",
      "Add label peachy.\n",
      "Add label smax.\n",
      "Add label sports-watch.\n",
      "Add label topic-news.\n"
     ]
    }
   ],
   "source": [
    "for service in services:\n",
    "    textcat.add_label(service)\n",
    "    print(\"Add label %s.\" % (service))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(tokenizer, textcat, docs, cats, verbose=False):\n",
    "    y_true = [max(cat['cats'].items(), key=lambda x:x[1])[0] for cat in cats]\n",
    "    #y_true = [[cat['cats'][service] for service in services] for cat in cats]\n",
    "    y_pred = []\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        prediction = max(doc.cats.items(), key=lambda x:x[1])[0]  # 予測のサービス名\n",
    "        #prediction = services.index(prediction)\n",
    "        #one_hot_prediction = [False for _ in services]\n",
    "        #one_hot_prediction[services.index(prediction)] = True\n",
    "        #y_pred.append(one_hot_prediction)\n",
    "        y_pred.append(prediction)\n",
    "    #if verbose == False:\n",
    "    #    p, r, f1 = precision_recall_fscore_support(y_true, y_pred, average=\"micro\")[:3]    \n",
    "    #    #p, r, f1 = precision_recall_fscore_support(y_true, y_pred)[:3]    \n",
    "    #    return {\"textcat_p\": p, \"textcat_r\": r, \"textcat_f\": f1}\n",
    "    #else:\n",
    "    return classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "===== iteration 0/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34423576def44c5e9e4829201a7cb55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.78      0.84      0.81       790\n",
      "  it-life-hack       0.77      0.81      0.79       816\n",
      " kaden-channel       0.70      0.56      0.62       386\n",
      "livedoor-homme       0.73      0.63      0.68       545\n",
      "   movie-enter       0.82      0.87      0.85       629\n",
      "        peachy       0.75      0.79      0.77       800\n",
      "          smax       0.88      0.88      0.88       961\n",
      "  sports-watch       0.90      0.85      0.87       366\n",
      "    topic-news       0.82      0.80      0.81       370\n",
      "\n",
      "      accuracy                           0.80      5663\n",
      "     macro avg       0.79      0.78      0.79      5663\n",
      "  weighted avg       0.80      0.80      0.80      5663\n",
      "\n",
      "===== iteration 1/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9d1362c40844cf855768013647e503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.86      0.82       790\n",
      "  it-life-hack       0.80      0.82      0.81       816\n",
      " kaden-channel       0.72      0.61      0.66       386\n",
      "livedoor-homme       0.76      0.66      0.71       545\n",
      "   movie-enter       0.84      0.88      0.86       629\n",
      "        peachy       0.76      0.79      0.78       800\n",
      "          smax       0.88      0.89      0.89       961\n",
      "  sports-watch       0.90      0.86      0.88       366\n",
      "    topic-news       0.84      0.82      0.83       370\n",
      "\n",
      "      accuracy                           0.81      5663\n",
      "     macro avg       0.81      0.80      0.80      5663\n",
      "  weighted avg       0.81      0.81      0.81      5663\n",
      "\n",
      "===== iteration 2/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349c5ea2e4f742cca923a6bc67f576b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.79      0.85      0.82       790\n",
      "  it-life-hack       0.82      0.82      0.82       816\n",
      " kaden-channel       0.74      0.64      0.69       386\n",
      "livedoor-homme       0.76      0.68      0.71       545\n",
      "   movie-enter       0.85      0.89      0.87       629\n",
      "        peachy       0.79      0.79      0.79       800\n",
      "          smax       0.88      0.90      0.89       961\n",
      "  sports-watch       0.88      0.88      0.88       366\n",
      "    topic-news       0.85      0.82      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 3/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7cefcaea744d359a41495180c844d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.84      0.82       790\n",
      "  it-life-hack       0.81      0.81      0.81       816\n",
      " kaden-channel       0.73      0.65      0.69       386\n",
      "livedoor-homme       0.76      0.67      0.71       545\n",
      "   movie-enter       0.85      0.88      0.86       629\n",
      "        peachy       0.77      0.79      0.78       800\n",
      "          smax       0.87      0.90      0.89       961\n",
      "  sports-watch       0.89      0.87      0.88       366\n",
      "    topic-news       0.84      0.81      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.81      0.80      0.81      5663\n",
      "  weighted avg       0.81      0.82      0.81      5663\n",
      "\n",
      "===== iteration 4/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe41135c009446182e8909f98f4e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.85      0.83       790\n",
      "  it-life-hack       0.82      0.81      0.81       816\n",
      " kaden-channel       0.74      0.66      0.70       386\n",
      "livedoor-homme       0.76      0.70      0.73       545\n",
      "   movie-enter       0.85      0.88      0.87       629\n",
      "        peachy       0.78      0.80      0.79       800\n",
      "          smax       0.87      0.90      0.89       961\n",
      "  sports-watch       0.88      0.87      0.88       366\n",
      "    topic-news       0.84      0.82      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 5/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511f1168eabc42ccbfbc8697881711e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.85      0.83       790\n",
      "  it-life-hack       0.81      0.82      0.81       816\n",
      " kaden-channel       0.75      0.65      0.70       386\n",
      "livedoor-homme       0.76      0.69      0.72       545\n",
      "   movie-enter       0.86      0.88      0.87       629\n",
      "        peachy       0.79      0.80      0.80       800\n",
      "          smax       0.88      0.91      0.89       961\n",
      "  sports-watch       0.88      0.87      0.87       366\n",
      "    topic-news       0.84      0.81      0.82       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 6/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8ea680b43e4fe0b49ed5614353d6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.85      0.82       790\n",
      "  it-life-hack       0.81      0.82      0.81       816\n",
      " kaden-channel       0.76      0.66      0.71       386\n",
      "livedoor-homme       0.75      0.69      0.72       545\n",
      "   movie-enter       0.87      0.89      0.88       629\n",
      "        peachy       0.79      0.80      0.80       800\n",
      "          smax       0.88      0.91      0.90       961\n",
      "  sports-watch       0.89      0.86      0.88       366\n",
      "    topic-news       0.84      0.82      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.82      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 7/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e7b96c400f4078b58543d26f1850a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.85      0.82       790\n",
      "  it-life-hack       0.82      0.81      0.82       816\n",
      " kaden-channel       0.73      0.66      0.69       386\n",
      "livedoor-homme       0.75      0.69      0.71       545\n",
      "   movie-enter       0.87      0.90      0.88       629\n",
      "        peachy       0.80      0.81      0.80       800\n",
      "          smax       0.88      0.91      0.90       961\n",
      "  sports-watch       0.89      0.86      0.87       366\n",
      "    topic-news       0.84      0.81      0.82       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 8/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398a10d790034c46ab92b635d0254fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.85      0.83       790\n",
      "  it-life-hack       0.82      0.82      0.82       816\n",
      " kaden-channel       0.74      0.67      0.70       386\n",
      "livedoor-homme       0.75      0.68      0.71       545\n",
      "   movie-enter       0.87      0.89      0.88       629\n",
      "        peachy       0.79      0.80      0.80       800\n",
      "          smax       0.89      0.91      0.90       961\n",
      "  sports-watch       0.88      0.86      0.87       366\n",
      "    topic-news       0.83      0.81      0.82       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 9/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6408c8953c74293af577d0edb46e92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8dca1a08cb7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mprocessed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mpercentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrehearse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "n_iter = 20\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    textcat = nlp.pipeline[-1][-1]\n",
    "    optimizer = textcat.begin_training() # NOTE\n",
    "    print(\"Training the model...\")\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "    num_samples = len(train_data)\n",
    "    for i in range(n_iter):\n",
    "        print('===== iteration {}/{} ====='.format(i, n_iter))\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)  # generator\n",
    "        processed = 0\n",
    "        for i, batch in tqdm(enumerate(batches)):\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            processed += len(batch)\n",
    "            percentage = processed / num_samples * 100.0\n",
    "            #if i % 20 == 0:\n",
    "            #  print(\"  %5.2f %% of epoch done. batch size = %d\" % (percentage, len(batch)))\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            # evaluate on the dev data split off in load_data()\n",
    "            #scores = evaluate(nlp.tokenizer, textcat, val_docs, val_cats, verbose=True)\n",
    "            report = evaluate(nlp.tokenizer, textcat, val_docs, val_cats, verbose=True)\n",
    "        #print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "            print(report)\n",
    "        #print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "        #print(\n",
    "        #    \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(  # print a simple table\n",
    "        #        losses[\"textcat\"],\n",
    "        #        scores[\"textcat_p\"],\n",
    "        #        scores[\"textcat_r\"],\n",
    "        #        scores[\"textcat_f\"],\n",
    "        #    )\n",
    "        #)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E001] No component 'textcat' found in pipeline. Available names: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1ee0b518fc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'textcat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/joki/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mremove_pipe\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mremoved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mENABLE_PIPELINE_ANALYSIS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E001] No component 'textcat' found in pipeline. Available names: []"
     ]
    }
   ],
   "source": [
    "nlp.remove_pipe('textcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add label dokujo-tsushin.\n",
      "Add label it-life-hack.\n",
      "Add label kaden-channel.\n",
      "Add label livedoor-homme.\n",
      "Add label movie-enter.\n",
      "Add label peachy.\n",
      "Add label smax.\n",
      "Add label sports-watch.\n",
      "Add label topic-news.\n"
     ]
    }
   ],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "for label in services:\n",
    "    textcat.add_label(label)\n",
    "    print(\"Add label %s.\" % (label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chakin\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/3f/ca2f63451c0ab47970a6ab1d39d96118e70b6e73125529cea767c31368a3/chakin-0.0.8-py3-none-any.whl\n",
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/93/c6011037f24e3106d13f3be55297bf84ece2bf15b278cc4776339dc52db5/gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting progressbar2>=3.20.0\n",
      "  Using cached https://files.pythonhosted.org/packages/16/68/adc395e0a3c86571081c8a2e2daaa5b58270f6854276a089a0e9b5fa2c33/progressbar2-3.47.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.20.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from chakin) (0.25.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from chakin) (1.13.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from gensim) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Collecting python-utils>=2.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas>=0.20.1->chakin) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas>=0.20.1->chakin) (2.8.1)\n",
      "Collecting boto>=2.32\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 39.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.10.45)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.45 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.45)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-1.9.0-cp37-none-any.whl size=73088 sha256=089289bf274ceecefeef575b030d860ae0b6e36215b3f338b9436cc535601716\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ab/10/93/5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "Successfully built smart-open\n",
      "Installing collected packages: python-utils, progressbar2, chakin, boto, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 chakin-0.0.8 gensim-3.8.1 progressbar2-3.47.0 python-utils-2.3.0 smart-open-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chakin gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Name  Dimension     Corpus VocabularySize  \\\n",
      "6                fastText(ja)        300  Wikipedia           580K   \n",
      "22  word2vec.Wiki-NEologd.50d         50  Wikipedia           335K   \n",
      "\n",
      "                Method  Language                 Author  \n",
      "6             fastText  Japanese               Facebook  \n",
      "22  word2vec + NEologd  Japanese  Shiroyagi Corporation  \n"
     ]
    }
   ],
   "source": [
    "import chakin\n",
    "chakin.search(lang='Japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100% ||                                      | Time:  0:00:53  22.7 MiB/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./cc.ja.300.vec.gz'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chakin.download(number=6, save_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私の環境では10分半ほどかかりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 30s, sys: 3.46 s, total: 10min 34s\n",
      "Wall time: 10min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format('cc.ja.300.vec.gz', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.reset_vectors(width=wv.vectors.shape[1])\n",
    "for word in wv.vocab.keys():\n",
    "    nlp.vocab[word]\n",
    "    nlp.vocab.set_vector(word, wv[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.vectors.name = 'fastText'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2113837, 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "with cupy.cuda.Device(0):\n",
    "    nlp.vocab.vectors.data = cupy.asarray(nlp.vocab.vectors.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "===== iteration 0/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f61ee847594005944f6d012d77225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.73      0.81      0.77       790\n",
      "  it-life-hack       0.73      0.78      0.75       816\n",
      " kaden-channel       0.68      0.41      0.51       386\n",
      "livedoor-homme       0.68      0.50      0.58       545\n",
      "   movie-enter       0.83      0.88      0.85       629\n",
      "        peachy       0.70      0.74      0.72       800\n",
      "          smax       0.86      0.88      0.87       961\n",
      "  sports-watch       0.84      0.87      0.85       366\n",
      "    topic-news       0.78      0.81      0.79       370\n",
      "\n",
      "      accuracy                           0.76      5663\n",
      "     macro avg       0.76      0.74      0.74      5663\n",
      "  weighted avg       0.76      0.76      0.76      5663\n",
      "\n",
      "===== iteration 1/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a9c55f8d424bf4aaf3df7a79ef0893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.76      0.82      0.79       790\n",
      "  it-life-hack       0.78      0.81      0.80       816\n",
      " kaden-channel       0.71      0.52      0.60       386\n",
      "livedoor-homme       0.72      0.58      0.64       545\n",
      "   movie-enter       0.83      0.89      0.86       629\n",
      "        peachy       0.75      0.76      0.75       800\n",
      "          smax       0.87      0.90      0.89       961\n",
      "  sports-watch       0.84      0.88      0.86       366\n",
      "    topic-news       0.80      0.82      0.81       370\n",
      "\n",
      "      accuracy                           0.79      5663\n",
      "     macro avg       0.79      0.78      0.78      5663\n",
      "  weighted avg       0.79      0.79      0.79      5663\n",
      "\n",
      "===== iteration 2/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7f8a4a979f48df82cf8c01372a44d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.78      0.82      0.80       790\n",
      "  it-life-hack       0.79      0.83      0.81       816\n",
      " kaden-channel       0.73      0.59      0.66       386\n",
      "livedoor-homme       0.75      0.64      0.69       545\n",
      "   movie-enter       0.85      0.89      0.87       629\n",
      "        peachy       0.77      0.78      0.77       800\n",
      "          smax       0.88      0.91      0.89       961\n",
      "  sports-watch       0.85      0.89      0.87       366\n",
      "    topic-news       0.81      0.81      0.81       370\n",
      "\n",
      "      accuracy                           0.81      5663\n",
      "     macro avg       0.80      0.79      0.80      5663\n",
      "  weighted avg       0.81      0.81      0.81      5663\n",
      "\n",
      "===== iteration 3/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fab23414ecb4a579e589a99c3735d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.79      0.82      0.81       790\n",
      "  it-life-hack       0.80      0.83      0.82       816\n",
      " kaden-channel       0.72      0.62      0.67       386\n",
      "livedoor-homme       0.76      0.65      0.70       545\n",
      "   movie-enter       0.86      0.90      0.88       629\n",
      "        peachy       0.77      0.79      0.78       800\n",
      "          smax       0.89      0.91      0.90       961\n",
      "  sports-watch       0.86      0.89      0.87       366\n",
      "    topic-news       0.84      0.83      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.81      0.80      0.81      5663\n",
      "  weighted avg       0.81      0.82      0.81      5663\n",
      "\n",
      "===== iteration 4/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d237ce51d26473781da737046875857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.80      0.82      0.81       790\n",
      "  it-life-hack       0.81      0.83      0.82       816\n",
      " kaden-channel       0.72      0.63      0.67       386\n",
      "livedoor-homme       0.77      0.67      0.72       545\n",
      "   movie-enter       0.87      0.90      0.88       629\n",
      "        peachy       0.78      0.79      0.78       800\n",
      "          smax       0.89      0.92      0.90       961\n",
      "  sports-watch       0.87      0.89      0.88       366\n",
      "    topic-news       0.83      0.83      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.81      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 5/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3af7a0ff4944dd79d4bc84dc5a560c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.81      0.83      0.82       790\n",
      "  it-life-hack       0.80      0.85      0.82       816\n",
      " kaden-channel       0.75      0.64      0.69       386\n",
      "livedoor-homme       0.77      0.67      0.71       545\n",
      "   movie-enter       0.86      0.90      0.88       629\n",
      "        peachy       0.79      0.78      0.78       800\n",
      "          smax       0.89      0.91      0.90       961\n",
      "  sports-watch       0.87      0.89      0.88       366\n",
      "    topic-news       0.83      0.84      0.83       370\n",
      "\n",
      "      accuracy                           0.82      5663\n",
      "     macro avg       0.82      0.81      0.81      5663\n",
      "  weighted avg       0.82      0.82      0.82      5663\n",
      "\n",
      "===== iteration 6/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e9e85d26e349b79504a47bcb07360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.82      0.84      0.83       790\n",
      "  it-life-hack       0.81      0.85      0.83       816\n",
      " kaden-channel       0.74      0.65      0.69       386\n",
      "livedoor-homme       0.77      0.67      0.72       545\n",
      "   movie-enter       0.87      0.90      0.88       629\n",
      "        peachy       0.79      0.80      0.79       800\n",
      "          smax       0.90      0.92      0.91       961\n",
      "  sports-watch       0.88      0.88      0.88       366\n",
      "    topic-news       0.83      0.84      0.83       370\n",
      "\n",
      "      accuracy                           0.83      5663\n",
      "     macro avg       0.82      0.82      0.82      5663\n",
      "  weighted avg       0.83      0.83      0.83      5663\n",
      "\n",
      "===== iteration 7/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb81e31c8fae4f0c95a833225ad3f40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.83      0.85      0.84       790\n",
      "  it-life-hack       0.82      0.85      0.83       816\n",
      " kaden-channel       0.74      0.66      0.70       386\n",
      "livedoor-homme       0.76      0.69      0.72       545\n",
      "   movie-enter       0.87      0.91      0.89       629\n",
      "        peachy       0.80      0.80      0.80       800\n",
      "          smax       0.89      0.92      0.90       961\n",
      "  sports-watch       0.89      0.89      0.89       366\n",
      "    topic-news       0.83      0.85      0.84       370\n",
      "\n",
      "      accuracy                           0.83      5663\n",
      "     macro avg       0.83      0.82      0.82      5663\n",
      "  weighted avg       0.83      0.83      0.83      5663\n",
      "\n",
      "===== iteration 8/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427e21a9b14f498c9bcc47cc362419aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.83      0.84      0.84       790\n",
      "  it-life-hack       0.81      0.84      0.83       816\n",
      " kaden-channel       0.74      0.65      0.69       386\n",
      "livedoor-homme       0.77      0.70      0.73       545\n",
      "   movie-enter       0.87      0.90      0.88       629\n",
      "        peachy       0.80      0.81      0.81       800\n",
      "          smax       0.89      0.91      0.90       961\n",
      "  sports-watch       0.89      0.90      0.89       366\n",
      "    topic-news       0.83      0.84      0.84       370\n",
      "\n",
      "      accuracy                           0.83      5663\n",
      "     macro avg       0.83      0.82      0.82      5663\n",
      "  weighted avg       0.83      0.83      0.83      5663\n",
      "\n",
      "===== iteration 9/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ec438ada27413d9ad595480e1bfe8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.81      0.85      0.83       816\n",
      " kaden-channel       0.74      0.66      0.69       386\n",
      "livedoor-homme       0.77      0.70      0.73       545\n",
      "   movie-enter       0.87      0.90      0.88       629\n",
      "        peachy       0.82      0.81      0.81       800\n",
      "          smax       0.90      0.92      0.91       961\n",
      "  sports-watch       0.89      0.89      0.89       366\n",
      "    topic-news       0.83      0.85      0.84       370\n",
      "\n",
      "      accuracy                           0.83      5663\n",
      "     macro avg       0.83      0.82      0.83      5663\n",
      "  weighted avg       0.83      0.83      0.83      5663\n",
      "\n",
      "===== iteration 10/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cce4e9422114d95a1a853856d77a645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.81      0.85      0.83       816\n",
      " kaden-channel       0.75      0.66      0.70       386\n",
      "livedoor-homme       0.78      0.71      0.74       545\n",
      "   movie-enter       0.87      0.90      0.89       629\n",
      "        peachy       0.81      0.81      0.81       800\n",
      "          smax       0.90      0.92      0.91       961\n",
      "  sports-watch       0.88      0.90      0.89       366\n",
      "    topic-news       0.83      0.83      0.83       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.82      0.83      5663\n",
      "  weighted avg       0.83      0.84      0.83      5663\n",
      "\n",
      "===== iteration 11/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5388f6beb02d4e17b10bd4cfd3f939b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.82      0.85      0.83       816\n",
      " kaden-channel       0.75      0.67      0.70       386\n",
      "livedoor-homme       0.77      0.71      0.74       545\n",
      "   movie-enter       0.86      0.90      0.88       629\n",
      "        peachy       0.81      0.81      0.81       800\n",
      "          smax       0.90      0.92      0.91       961\n",
      "  sports-watch       0.88      0.90      0.89       366\n",
      "    topic-news       0.82      0.82      0.82       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.83      0.84      0.83      5663\n",
      "\n",
      "===== iteration 12/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395cbc6866e54d3b870a732e9979d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.85      0.84       790\n",
      "  it-life-hack       0.82      0.85      0.83       816\n",
      " kaden-channel       0.76      0.67      0.71       386\n",
      "livedoor-homme       0.78      0.70      0.74       545\n",
      "   movie-enter       0.87      0.90      0.89       629\n",
      "        peachy       0.81      0.82      0.81       800\n",
      "          smax       0.90      0.91      0.91       961\n",
      "  sports-watch       0.88      0.90      0.89       366\n",
      "    topic-news       0.83      0.84      0.83       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n",
      "===== iteration 13/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c189930d6a5b4745a7d3566ccdc044fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.82      0.85      0.83       816\n",
      " kaden-channel       0.76      0.67      0.71       386\n",
      "livedoor-homme       0.78      0.71      0.74       545\n",
      "   movie-enter       0.87      0.90      0.89       629\n",
      "        peachy       0.81      0.81      0.81       800\n",
      "          smax       0.90      0.92      0.91       961\n",
      "  sports-watch       0.87      0.90      0.89       366\n",
      "    topic-news       0.85      0.84      0.84       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n",
      "===== iteration 14/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43791d5d7e5e47189a98daec998fd6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.81      0.85      0.83       816\n",
      " kaden-channel       0.76      0.66      0.71       386\n",
      "livedoor-homme       0.76      0.69      0.72       545\n",
      "   movie-enter       0.87      0.91      0.89       629\n",
      "        peachy       0.81      0.81      0.81       800\n",
      "          smax       0.89      0.92      0.90       961\n",
      "  sports-watch       0.88      0.90      0.89       366\n",
      "    topic-news       0.84      0.84      0.84       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.82      0.83      5663\n",
      "  weighted avg       0.83      0.84      0.83      5663\n",
      "\n",
      "===== iteration 15/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32717186ecad433099fd6149c4447e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.83      0.84      0.83       790\n",
      "  it-life-hack       0.82      0.84      0.83       816\n",
      " kaden-channel       0.76      0.67      0.71       386\n",
      "livedoor-homme       0.77      0.71      0.74       545\n",
      "   movie-enter       0.87      0.91      0.89       629\n",
      "        peachy       0.82      0.82      0.82       800\n",
      "          smax       0.89      0.92      0.91       961\n",
      "  sports-watch       0.89      0.91      0.90       366\n",
      "    topic-news       0.84      0.84      0.84       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n",
      "===== iteration 16/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261b645fd47045c29f54c21db6e7a489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.83      0.84      0.84       790\n",
      "  it-life-hack       0.83      0.85      0.84       816\n",
      " kaden-channel       0.76      0.66      0.71       386\n",
      "livedoor-homme       0.77      0.72      0.74       545\n",
      "   movie-enter       0.87      0.90      0.89       629\n",
      "        peachy       0.82      0.81      0.82       800\n",
      "          smax       0.89      0.92      0.91       961\n",
      "  sports-watch       0.90      0.90      0.90       366\n",
      "    topic-news       0.83      0.85      0.84       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n",
      "===== iteration 17/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9f0e785b4b4b87a26c4c0a961ff518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.83      0.86      0.84       816\n",
      " kaden-channel       0.77      0.67      0.71       386\n",
      "livedoor-homme       0.78      0.73      0.75       545\n",
      "   movie-enter       0.87      0.90      0.89       629\n",
      "        peachy       0.83      0.81      0.82       800\n",
      "          smax       0.89      0.92      0.91       961\n",
      "  sports-watch       0.90      0.90      0.90       366\n",
      "    topic-news       0.84      0.85      0.85       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.84      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n",
      "===== iteration 18/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f3c6e900bb4dc2a9cf5928a76098e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.84      0.84      0.84       790\n",
      "  it-life-hack       0.83      0.85      0.84       816\n",
      " kaden-channel       0.76      0.66      0.71       386\n",
      "livedoor-homme       0.78      0.72      0.75       545\n",
      "   movie-enter       0.87      0.91      0.89       629\n",
      "        peachy       0.81      0.81      0.81       800\n",
      "          smax       0.89      0.92      0.91       961\n",
      "  sports-watch       0.89      0.90      0.90       366\n",
      "    topic-news       0.84      0.85      0.84       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n",
      "===== iteration 19/20 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2f290d28e44a2c9f9217b75ec5f504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.83      0.84      0.84       790\n",
      "  it-life-hack       0.82      0.84      0.83       816\n",
      " kaden-channel       0.75      0.66      0.70       386\n",
      "livedoor-homme       0.78      0.71      0.75       545\n",
      "   movie-enter       0.87      0.91      0.89       629\n",
      "        peachy       0.81      0.81      0.81       800\n",
      "          smax       0.89      0.92      0.91       961\n",
      "  sports-watch       0.90      0.90      0.90       366\n",
      "    topic-news       0.83      0.85      0.84       370\n",
      "\n",
      "      accuracy                           0.84      5663\n",
      "     macro avg       0.83      0.83      0.83      5663\n",
      "  weighted avg       0.84      0.84      0.84      5663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "n_iter = 20\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    textcat = nlp.pipeline[-1][-1]\n",
    "    #optimizer = textcat.begin_training(pretrained_vectors='fastText') # NOTE\n",
    "    optimizer = textcat.begin_training() # NOTE\n",
    "    print(\"Training the model...\")\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "    num_samples = len(train_data)\n",
    "    for i in range(n_iter):\n",
    "        print('===== iteration {}/{} ====='.format(i, n_iter))\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)  # generator\n",
    "        processed = 0\n",
    "        for i, batch in tqdm(enumerate(batches)):\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            processed += len(batch)\n",
    "            percentage = processed / num_samples * 100.0\n",
    "            #if i % 20 == 0:\n",
    "            #  print(\"  %5.2f %% of epoch done. batch size = %d\" % (percentage, len(batch)))\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            # evaluate on the dev data split off in load_data()\n",
    "            #scores = evaluate(nlp.tokenizer, textcat, val_docs, val_cats, verbose=True)\n",
    "            report = evaluate(nlp.tokenizer, textcat, val_docs, val_cats, verbose=True)\n",
    "        #print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "            print(report)\n",
    "        #print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "        #print(\n",
    "        #    \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(  # print a simple table\n",
    "        #        losses[\"textcat\"],\n",
    "        #        scores[\"textcat_p\"],\n",
    "        #        scores[\"textcat_r\"],\n",
    "        #        scores[\"textcat_f\"],\n",
    "        #    )\n",
    "        #)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "net = BertForSequenceClassification.from_pretrained('bert-base-japanese-whole-word-masking', num_labels=9)\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このニューラルネットワークの構造をnetron (https://github.com/lutzroeder/netron) というツールを用いて可視化すると次のようになります。\n",
    "<img src=\"../figures/bert_classifier_netron.png\" alt=\"bert_classifier_netron\" width=\"150\">\n",
    "BERTモデルの構造が `BertModel` に押し込められているため、やけにシンプルに見えますが、ここではあまり深く考えないようにします。\n",
    "\n",
    "PyTorchを用いてディープラーニングを実装する際には"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "\n",
    "import re\n",
    "import mojimoji\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "        # 半角、全角の変換\n",
    "        text = mojimoji.han_to_zen(text)\n",
    "        # 改行、半角スペース、全角スペースを削除\n",
    "        text = re.sub('\\r', '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('　', '', text)\n",
    "        text = re.sub(' ', '', text)\n",
    "        # 数字文字の一律「0」化\n",
    "        text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
    "        return tokenizer.tokenize(text)\n",
    "    \n",
    "TEXT = Field(\n",
    "    sequential=True,  \n",
    "    tokenize=tokenizer_with_preprocessing, \n",
    "    use_vocab=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    batch_first=True,\n",
    "    fix_length=512,\n",
    "    init_token='[CLS]',\n",
    "    eos_token='[SEP]',\n",
    "    pad_token='[PAD]',\n",
    "    unk_token='[UNK]'\n",
    ")\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "train, val, test = TabularDataset.splits(\n",
    "    path='.', train='train.tsv', validation='val.tsv', test='test.tsv', format='tsv', \n",
    "    fields=[('body', TEXT), ('service', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=1)\n",
    "TEXT.vocab.stoi = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Iterator\n",
    "batch_size = 32\n",
    "#train_iter, val_iter, test_iter = Iterator.splits((train, val, test), batch_size=batch_size, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iter = Iterator(train, batch_size, train=True, device=device)\n",
    "val_iter = Iterator(val, batch_size, train=False, sort=False, device=device)\n",
    "test_iter = Iterator(test, batch_size, train=False, sort=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_dict = {'train': train_iter, 'val': val_iter, 'test': test_iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "net.to('cuda')\n",
    "batch = next(iter(train_iter))\n",
    "inputs = batch.body[0]\n",
    "labels = batch.service\n",
    "loss, logit = net(inputs, labels=labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.classifier.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "    {'params': net.classifier.parameters(), 'lr': 5e-5}\n",
    "], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./logs/' + datetime.today().isoformat(timespec='seconds'))\n",
    "\n",
    "def train_model(net, iterator_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    iteration = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for batch in iterator_dict[phase]:\n",
    "                inputs = batch.body[0]\n",
    "                labels = batch.service\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    loss, logit = net(input_ids=inputs, labels=labels)\n",
    "                    #print(loss, logit)\n",
    "                    _, preds = torch.max(logit, 1)\n",
    "                    #predictions.append(preds.cpu().numpy())\n",
    "                    #ground_truths.append(labels.data.cpu().numpy())\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            acc = (torch.sum(preds == labels.data)).double() / batch_size\n",
    "                            print('iteration {} || Loss: {:.4f} || acc {}'.format(\n",
    "                                iteration, loss.item(), acc.item()))\n",
    "                            writer.add_scalar(\"Loss vs Iteration/{}\".format(phase), loss.item(), iteration)\n",
    "                            writer.add_scalar(\"Accuracy vs Iteration/{}\".format(phase), acc.item(), iteration)\n",
    "                        iteration += 1\n",
    "                    \n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    #print(preds, labels.data)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = epoch_loss / len(iterator_dict[phase].dataset)\n",
    "        epoch_acc = epoch_corrects.double() / len(iterator_dict[phase].dataset)\n",
    "        writer.add_scalar(\"Loss vs Epoch/{}\".format(phase), epoch_loss, epoch + 1)\n",
    "        writer.add_scalar(\"Accuracy vs Epoch/{}\".format(phase), epoch_acc, epoch + 1)\n",
    "        \n",
    "        print('Epoch {}/{} | {} | Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            epoch + 1, num_epochs, phase, epoch_loss, epoch_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100 \n",
    "net_trained = train_model(net, iterator_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価と比較\n",
    "\n",
    "まずBoWからはじめよう\n",
    "\n",
    "## まとめ\n",
    "\n",
    "BoW、CNN、BERT\n",
    "\n",
    "難しいタスクならBERT試すのもありかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [(Part 1) tensorflow2でhuggingfaceのtransformersを使ってBERTを文書分類モデルに転移学習する](https://tksmml.hatenablog.com/entry/2019/10/22/215000)\n",
    "- [(Part 2) tensorflow 2 でhugging faceのtransformers公式のBERT日本語学習済みモデルを文書分類モデルにfine-tuningする](https://tksmml.hatenablog.com/entry/2019/12/15/090900)\n",
    "- [All Models and checkpoints](https://huggingface.co/models)\n",
    "- [Working with GPU packages](https://docs.anaconda.com/anaconda/user-guide/tasks/gpu-packages/)\n",
    "- [gensimとPyTorchを使ったlive doorニュースコーパスのテキスト分類](https://www.pytry3g.com/entry/2018/04/03/194202)\n",
    "- [bert-japanese](https://github.com/cl-tohoku/bert-japanese)\n",
    "- [DocumentClassificationUsingBERT-Japanese](https://github.com/nekoumei/DocumentClassificationUsingBERT-Japanese)\n",
    "- [torchtext](https://torchtext.readthedocs.io/en/latest/index.html)\n",
    "- [FX予測 : PyTorchのBERTで経済ニュース解析](https://qiita.com/THERE2/items/8b7c94787911fad8daa6)\n",
    "- [torchtextで簡単にDeepな自然言語処理](https://qiita.com/itok_msi/items/1f3746f7e89a19dafac5)\n",
    "- [transformers](https://github.com/huggingface/transformers)\n",
    "- [BERTを使った文章要約 [身内向け]](https://qiita.com/IwasakiYuuki/items/25f5bbcde4f82dff7f1a)\n",
    "- [MeCab + Gensim による日本語の自然言語処理](https://www.koi.mashykom.com/nlp.html)\n",
    "- [論文解説 Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (GNMT)](http://deeplearning.hatenablog.com/entry/gnmt)\n",
    "- [BERT with SentencePiece で日本語専用の pre-trained モデルを学習し、それを基にタスクを解く](https://techlife.cookpad.com/entry/2018/12/04/093000)\n",
    "- [はじめての自然言語処理](https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
