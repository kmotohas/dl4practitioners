{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章\n",
    "\n",
    "## 機械学習モデル開発のワークフローと本章で扱う内容\n",
    "\n",
    "なお、動作確認は以下の環境で行いました。\n",
    "\n",
    "- Machine (AWS EC2 p2.xlargeインスタンス)\n",
    "    - OS: Ubuntu 16.04\n",
    "    - CPU: Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
    "    - RAM: 64GB \n",
    "    - GPU: NVIDIA Tesla K80\n",
    "- Python\n",
    "    - Python 3.7.5\n",
    "    - PyTorch 1.3.1\n",
    "    - torchtext 0.4.0\n",
    "    - transformers 2.3.0\n",
    "\n",
    "## 文書分類ハンズオン\n",
    "\n",
    "### 本章で扱う自然言語処理ツールの解説\n",
    "\n",
    "#### Transformers\n",
    "\n",
    "Transformersで用いることのできるモデルのリストはHugging Faceのホームページ (https://huggingface.co/models) にて公開されています。\n",
    "\n",
    "-  `bert-base-japanese`:\n",
    "-  `bert-base-japanese-whole-word-masking`\n",
    "-  `bert-base-japanese-char`\n",
    "-  `bert-base-japanese-char-whole-word-masking`\n",
    "\n",
    "Transformersは、FaceBookが開発しているPyTorchおよび、GoogleのTensorFlowのバージョン2.0以降に対応しています。ここではPyTorchを用いることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境によってインストールコマンドが異なります。https://pytorch.org/get-started/を参照してください。\n",
    "# 2019年12月現在、NVIDIAのGPUを搭載したLinuxマシンにAnacondaでPyTorchをインストールするコマンドは以下の通りです。\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# LinuxでかつGPUがない場合は !conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "便利なtorchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install torchtext -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (4.41.0)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (1.10.45)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: click in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.45 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (1.13.45)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bert-base-japanese*` は形態素解析のライブラリとして内部でMeCabを用いているので、`mecab-python3` もインストールしておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、以降で補助的に利用するライブラリもインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: seaborn in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.9.0)\n",
      "Collecting mojimoji\n",
      "  Downloading https://files.pythonhosted.org/packages/10/2d/f5d58e74af1c1b4eeea66ecc14f35ae8f275f39bc7158ba51a6e8a86dfdf/mojimoji-0.0.9.post0.tar.gz\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (1.17.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from seaborn) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (42.0.2.post20191203)\n",
      "Building wheels for collected packages: mojimoji\n",
      "  Building wheel for mojimoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mojimoji: filename=mojimoji-0.0.9-cp37-cp37m-linux_x86_64.whl size=116391 sha256=c849771a8fb83d62824d13e869c1491f75990b1459b63cc0b5106e40c61bf63c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/67/f0/6e/03e5c5017afc8230e19abeacad57189138207fea2f5dd71880\n",
      "Successfully built mojimoji\n",
      "Installing collected packages: mojimoji\n",
      "Successfully installed mojimoji-0.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn seaborn mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn\n",
    "- mojimoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTを用いて日本語の文章を分類する手順はおおまかに書くと以下のようになります。\n",
    "\n",
    "1. aaa\n",
    "2. aaa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['いつも',\n",
       " 'プレゼンテーション',\n",
       " 'の',\n",
       " '撮影',\n",
       " 'に',\n",
       " '無',\n",
       " '##音',\n",
       " 'カメラ',\n",
       " '##アプリ',\n",
       " 'を',\n",
       " 'ご',\n",
       " '利用',\n",
       " 'いただ',\n",
       " '##き',\n",
       " 'ありがとう',\n",
       " 'ござい',\n",
       " 'ます',\n",
       " '。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "tokenizer.tokenize('いつもプレゼンテーションの撮影に無音カメラアプリをご利用いただきありがとうございます。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "#### livedoor ニュースコーパス\n",
    "\n",
    "今回は日本語における自然言語処理の試験用データセットとしてしばしば用いられる「livedoor ニュースコーパス」を用います。\n",
    "\n",
    "livedoorニュースはもともと株式会社ライブドアが運営するニュースサイトでしたが、株式会社ライブドアが旧ハンゲームジャパン株式会社であるNHN Japan株式会社に買収され、現在はNHN Japanが社名変更したLINE株式会社により運営されています。livedoorニュースの記事の一部には「クリエイティブ・コモンズライセンス『表示 – 改変禁止』」が適用されており、営利目的を含めて再配布可能となっています。該当するニュース記事を2012年9月上旬に株式会社ロンウイットが収集し、HTMLタグの除去などクリーニングを施した状態で公開しているのが「livedoor ニュースコーパス」です。\n",
    "\n",
    "livedoor ニュースコーパスは以下のリンクよりダウンロード可能です。\n",
    "\n",
    "https://www.rondhuit.com/download.html#ldcc\n",
    "\n",
    "オープンソースの全文検索システムApache Solrで扱いやすいようXML形式でニュースが格納されている `livedoor-news-data.tar.gz` と、シンプルに各々のニュースをテキストファイルとして扱っている `ldcc-20140209.tar.gz` が公開されています。\n",
    "\n",
    "今回は後者の `ldcc-20140209.tar.gz` をダウンロードしてください。`tar xzvf ldcc-20140209.tar.gz` などにより解凍すると `text` という名前のディレクトリが出てきます。以下のPythonスクリプトを実行するとコーパスのダウンロードと圧縮ファイルの解凍が行われ、カレントディレクトリに `text` ディレクトリが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# dataディレクトリの作成\n",
    "#os.makedirs('data', exist_ok=True)\n",
    "\n",
    "url = 'https://www.rondhuit.com/download/ldcc-20140209.tar.gz'\n",
    "file_name = 'ldcc-20140209.tar.gz'\n",
    "\n",
    "# dataディレクトリへのlivedoor ニュースコーパスのダウンロードと解凍\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    # tar.gzファイルを読み込み\n",
    "    with tarfile.open(file_name) as tar:\n",
    "        tar.extractall()\n",
    "    # tar.gzファイルを消去\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` ディレクトリの中身の構造は以下の通りです。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "├── it-life-hack\n",
    "├── kaden-channel\n",
    "├── livedoor-homme\n",
    "├── movie-enter\n",
    "├── peachy\n",
    "├── smax\n",
    "├── sports-watch\n",
    "└── topic-news\n",
    "```\n",
    "\n",
    "`dokujo-tsushin` から `topic-news` はディレクトリであり、それぞれにニュース記事のテキストが格納されています。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "│   ├── LICENSE.txt\n",
    "│   ├── dokujo-tsushin-4778030.txt\n",
    "│   ├── dokujo-tsushin-4778031.txt\n",
    "│   ├── dokujo-tsushin-4782522.txt\n",
    "...（以下略）\n",
    "```\n",
    "\n",
    "ニュース提供元は以下の9つです。記事の本文だけを見て、その記事がどのカテゴリに属しているのか（独女通信のニュースなのか、ITライフハックのニュースなのか、など）を判別する文書分類モデルを作成するのが本章の目的です。\n",
    "\n",
    "- 独女通信 (http://news.livedoor.com/category/vender/90/)\n",
    "- ITライフハック (http://news.livedoor.com/category/vender/223/)\n",
    "- 家電チャンネル (http://news.livedoor.com/category/vender/kadench/)\n",
    "- livedoor HOMME (http://news.livedoor.com/category/vender/homme/)\n",
    "- MOVIE ENTER (http://news.livedoor.com/category/vender/movie_enter/)\n",
    "- Peachy (http://news.livedoor.com/category/vender/ldgirls/)\n",
    "- エスマックス (http://news.livedoor.com/category/vender/smax/)\n",
    "- Sports Watch (http://news.livedoor.com/category/vender/208/)\n",
    "- トピックニュース (http://news.livedoor.com/category/vender/news/)\n",
    "\n",
    "ちなみに、上記サービスのうちいくつかはドメインが変わっていたり終了しているので一部リンクが切れています。それぞれの記事ファイル（dokujo-tsushin-4778030.txtなど）は以下のフォーマットで構成されています。\n",
    "\n",
    "- １行目: 記事のURL\n",
    "- ２行目: 記事の日付\n",
    "- ３行目: 記事のタイトル\n",
    "- ４行目以降： 記事の本文\n",
    "\n",
    "このままでは少し扱いづらいのでひとつのtsv (tab-separated values) にまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]\n",
    "index = ['url', 'datetime', 'title', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== processing dokujo-tsushin =====\n",
      "===== processing it-life-hack =====\n",
      "===== processing kaden-channel =====\n",
      "===== processing livedoor-homme =====\n",
      "===== processing movie-enter =====\n",
      "===== processing peachy =====\n",
      "===== processing smax =====\n",
      "===== processing sports-watch =====\n",
      "===== processing topic-news =====\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# あまりに短い文章は除く\n",
    "minimum_sentence_length = 32\n",
    "\n",
    "# 空のPandasのDataFrameを準備\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# 各サービスのディレクトリでループ\n",
    "for service in services:\n",
    "    print('===== processing {} ====='.format(service))\n",
    "    # ニュース記事をすべて指定\n",
    "    # パスの例は './text/dokujo-tsushin/dokujo-tsushin-4778030.txt'\n",
    "    # LICENSE.txt は除外\n",
    "    wild_card = os.path.join('text', service, service + '*.txt')\n",
    "    file_paths = glob.glob(wild_card)\n",
    "    # 各ニュース記事のファイルパスでループ\n",
    "    for file_path in file_paths:\n",
    "        # ファイルを開いて一行ずつ読み込む\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # tsv のカラムを辞書型で用意\n",
    "            series_dict = {'service': service}\n",
    "            for num, line in enumerate(lines):\n",
    "                #line = line.replace('\\n', '')  # 改行を削除\n",
    "                # 0, 1, 2行目はそれぞれURL, 日付, 記事タイトルに相当\n",
    "                if num < len(index):\n",
    "                    series_dict[index[num]] = line\n",
    "                # 3行目以降は本文\n",
    "                elif line != '\\n' and line != '':\n",
    "                    series_dict['body'] += line\n",
    "                # lineが空（段落の境目もしくはファイルの末尾）の場合\n",
    "                else:\n",
    "                    if '関連記事' in series_dict['body']:\n",
    "                        pass\n",
    "                    elif '関連リンク' in series_dict['body']:\n",
    "                        pass\n",
    "                    # PandasのSeriesを作成し、DataFrameに追加していく\n",
    "                    elif len(series_dict['body']) > minimum_sentence_length:\n",
    "                        s = pd.Series(series_dict)\n",
    "                        df = df.append(s, ignore_index=True)\n",
    "                    # bodyを初期化\n",
    "                    series_dict['body'] = ''\n",
    "print('done')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した `DataFrame` の最初の5行と最後の5行だけ抜き出して表示してみましょう。\n",
    "それぞれの行がひとつのニュース記事に対応していることより、0行から7366行の計7367個のニュース記事があることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56628</th>\n",
       "      <td>藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56629</th>\n",
       "      <td>ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56630</th>\n",
       "      <td>一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1      「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...   \n",
       "2      ●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...   \n",
       "56628  藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...   \n",
       "56629  ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...   \n",
       "56630  一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...   \n",
       "\n",
       "                         datetime         service  \\\n",
       "0      2011-10-13T15:28:00+0900\\n  dokujo-tsushin   \n",
       "1      2011-10-13T15:28:00+0900\\n  dokujo-tsushin   \n",
       "2      2011-10-13T15:28:00+0900\\n  dokujo-tsushin   \n",
       "56628  2012-06-21T20:32:00+0900\\n      topic-news   \n",
       "56629  2012-06-21T20:32:00+0900\\n      topic-news   \n",
       "56630  2012-06-21T20:32:00+0900\\n      topic-news   \n",
       "\n",
       "                                            title  \\\n",
       "0              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "1              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "2              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "56628  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56629  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56630  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "\n",
       "                                                     url  \n",
       "0      http://news.livedoor.com/article/detail/593428...  \n",
       "1      http://news.livedoor.com/article/detail/593428...  \n",
       "2      http://news.livedoor.com/article/detail/593428...  \n",
       "56628  http://news.livedoor.com/article/detail/668154...  \n",
       "56629  http://news.livedoor.com/article/detail/668154...  \n",
       "56630  http://news.livedoor.com/article/detail/668154...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.head(3), df.tail(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smax              9212\n",
       "it-life-hack      8400\n",
       "dokujo-tsushin    8296\n",
       "peachy            7934\n",
       "movie-enter       6524\n",
       "livedoor-homme    5329\n",
       "kaden-channel     3818\n",
       "topic-news        3603\n",
       "sports-watch      3515\n",
       "Name: service, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f20db5241d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df['service'].value_counts()).plot(kind='bar', rot=45, ylim=(0, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...</td>\n",
       "      <td>2011-10-13T15:28:00+0900\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/593428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56628</th>\n",
       "      <td>藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56629</th>\n",
       "      <td>ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56630</th>\n",
       "      <td>一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...</td>\n",
       "      <td>2012-06-21T20:32:00+0900\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n</td>\n",
       "      <td>http://news.livedoor.com/article/detail/668154...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1      「『スッピンのほうがいい』とは、スッピンでもメイク時と同じくらいかわいい女性が好みだという意...   \n",
       "2      ●「女の子は多少、太ってるくらいがかわいいよ」\\n女性は年中、ダイエットと向き合っている。ど...   \n",
       "56628  藤村修官房長官は20日、記者会見を開き、「政府として軍事転用などという考えは一切持っていない...   \n",
       "56629  ニュースを受け、韓国のネット掲示板では、「日本は本当に怖い国だ」「日本がするなら我々もする」...   \n",
       "56630  一方で、「韓国、日本、台湾が全部核武装すれば真の平和が訪れるかもしれない」「各国の健全な良識...   \n",
       "\n",
       "                         datetime  service  \\\n",
       "0      2011-10-13T15:28:00+0900\\n        0   \n",
       "1      2011-10-13T15:28:00+0900\\n        0   \n",
       "2      2011-10-13T15:28:00+0900\\n        0   \n",
       "56628  2012-06-21T20:32:00+0900\\n        8   \n",
       "56629  2012-06-21T20:32:00+0900\\n        8   \n",
       "56630  2012-06-21T20:32:00+0900\\n        8   \n",
       "\n",
       "                                            title  \\\n",
       "0              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "1              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "2              「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音\\n   \n",
       "56628  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56629  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "56630  原子力基本法の改正に、韓国から「日本の核武装を阻止すべき」「我々も核武装だ」の声\\n   \n",
       "\n",
       "                                                     url  \n",
       "0      http://news.livedoor.com/article/detail/593428...  \n",
       "1      http://news.livedoor.com/article/detail/593428...  \n",
       "2      http://news.livedoor.com/article/detail/593428...  \n",
       "56628  http://news.livedoor.com/article/detail/668154...  \n",
       "56629  http://news.livedoor.com/article/detail/668154...  \n",
       "56630  http://news.livedoor.com/article/detail/668154...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['service'] = le.fit_transform(df.service.values)\n",
    "pd.concat([df.head(3), df.tail(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df[['body', 'service']]\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` をCSV (Comma-Separated Value) やTSV (Tab-Separated Value) で保存するには `pandas.DataFrame.to_csv` メソッドを呼び出します。ひとつ目の引数 `path_or_buf` には保存先のファイルパス（もしくはファイルオブジェクト）を指定し、ふたつ目の引数 `sep` には列のセパレーターを指定します。デフォルトでは `sep=','` となっており、セパレーターはカンマ、つまり `DataFrame` はCSVで保存されます。自然言語処理を行う場合、データ内にカンマが含まれていることがあるのでしばしばセパレーターとしてはタブ (`\\t`) が用いられます。ここでは `DataFrame` をTSVの形式で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv', sep='\\t', index=False)\n",
    "val_df.to_csv('val.tsv', sep='\\t', index=False)\n",
    "test_df.to_csv('test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ラベリング\n",
    "\n",
    "### 前処理\n",
    "\n",
    "\n",
    "\n",
    "#### 形態素解析\n",
    "#### ストップワード除去\n",
    "\n",
    "### 文書分類モデル\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\ndf = pd.read_csv('news.tsv', sep='\\t', index_col=0)\\ndf = df[['body', 'service']]\\ndf.head()\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv('news.tsv', sep='\\t', index_col=0)\n",
    "df = df[['body', 'service']]\n",
    "df.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import LabelEncoder\\nle = LabelEncoder()\\ndf['service'] = le.fit_transform(df.service.values)\\ndf.head()\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['service'] = le.fit_transform(df.service.values)\n",
    "df.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>先週前半は、嵐の前の静けさといった感じで、かなり平穏でした。それもあってニュースのネタ探しに...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>23日、千葉県総合スポーツセンター陸上競技場では、国際千葉駅伝が行われた。レースは、ケニアが...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>ゼロから始めるスマートフォン ZTEは19日（現地時間）、現在シンガポールで開催されている展...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>ドコモは2012年3月5日 、「ドコモwebメール」を2012年8月27日午前11時をもって...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>現在、全米で大ヒット継続中で、2年連続“最も好きな犯罪ドラマ”にも選ばれている人気海外ドラ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  service\n",
       "1536  先週前半は、嵐の前の静けさといった感じで、かなり平穏でした。それもあってニュースのネタ探しに...        1\n",
       "6175  23日、千葉県総合スポーツセンター陸上競技場では、国際千葉駅伝が行われた。レースは、ケニアが...        7\n",
       "5130  ゼロから始めるスマートフォン ZTEは19日（現地時間）、現在シンガポールで開催されている展...        6\n",
       "1123  ドコモは2012年3月5日 、「ドコモwebメール」を2012年8月27日午前11時をもって...        1\n",
       "3450  　現在、全米で大ヒット継続中で、2年連続“最も好きな犯罪ドラマ”にも選ばれている人気海外ドラ...        4"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>省エネ効果があり、従来の蛍光灯や電球と違って長期間使用が可能で、しかも明るいLEDライト。今...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>ＳＦ小説の巨匠ロバート・Ａ・ハインラインの傑作『宇宙の戦士』を映画化し、巨大昆虫と戦う兵士...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>昨年12月、大阪府立体育会館で開催された、ボクシング・WBA世界ダブルタイトルマッチにおいて...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>20日、ハロープロジェクトに所属するアイドルグループ「スマイレージ」のスタッフが管理するツイ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>先日ひと騒動あった不審なAndroidアプリの件、「ヘンなアプリに要注意！ データぶっこ抜き...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  service\n",
       "2513  省エネ効果があり、従来の蛍光灯や電球と違って長期間使用が可能で、しかも明るいLEDライト。今...        2\n",
       "3374  　ＳＦ小説の巨匠ロバート・Ａ・ハインラインの傑作『宇宙の戦士』を映画化し、巨大昆虫と戦う兵士...        4\n",
       "6048  昨年12月、大阪府立体育会館で開催された、ボクシング・WBA世界ダブルタイトルマッチにおいて...        7\n",
       "6894  20日、ハロープロジェクトに所属するアイドルグループ「スマイレージ」のスタッフが管理するツイ...        8\n",
       "1485  先日ひと騒動あった不審なAndroidアプリの件、「ヘンなアプリに要注意！ データぶっこ抜き...        1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "net = BertForSequenceClassification.from_pretrained('bert-base-japanese-whole-word-masking', num_labels=9)\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このニューラルネットワークの構造をnetron (https://github.com/lutzroeder/netron) というツールを用いて可視化すると次のようになります。\n",
    "<img src=\"../figures/bert_classifier_netron.png\" alt=\"bert_classifier_netron\" width=\"150\">\n",
    "BERTモデルの構造が `BertModel` に押し込められているため、やけにシンプルに見えますが、ここではあまり深く考えないようにします。\n",
    "\n",
    "PyTorchを用いてディープラーニングを実装する際には"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "\n",
    "import re\n",
    "import mojimoji\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "        # 半角、全角の変換\n",
    "        text = mojimoji.han_to_zen(text)\n",
    "        # 改行、半角スペース、全角スペースを削除\n",
    "        text = re.sub('\\r', '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('　', '', text)\n",
    "        text = re.sub(' ', '', text)\n",
    "        # 数字文字の一律「0」化\n",
    "        text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
    "        return tokenizer.tokenize(text)\n",
    "    \n",
    "TEXT = Field(\n",
    "    sequential=True,  \n",
    "    tokenize=tokenizer_with_preprocessing, \n",
    "    use_vocab=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    batch_first=True,\n",
    "    fix_length=512,\n",
    "    init_token='[CLS]',\n",
    "    eos_token='[SEP]',\n",
    "    pad_token='[PAD]',\n",
    "    unk_token='[UNK]'\n",
    ")\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "train, val, test = TabularDataset.splits(\n",
    "    path='.', train='train.tsv', validation='val.tsv', test='test.tsv', format='tsv', \n",
    "    fields=[('body', TEXT), ('service', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=1)\n",
    "TEXT.vocab.stoi = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Iterator\n",
    "batch_size = 32\n",
    "#train_iter, val_iter, test_iter = Iterator.splits((train, val, test), batch_size=batch_size, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iter = Iterator(train, batch_size, train=True, device=device)\n",
    "val_iter = Iterator(val, batch_size, train=False, sort=False, device=device)\n",
    "test_iter = Iterator(test, batch_size, train=False, sort=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_dict = {'train': train_iter, 'val': val_iter, 'test': test_iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnet.to('cuda')\\nbatch = next(iter(train_iter))\\ninputs = batch.body[0]\\nlabels = batch.service\\nloss, logit = net(inputs, labels=labels)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "net.to('cuda')\n",
    "batch = next(iter(train_iter))\n",
    "inputs = batch.body[0]\n",
    "labels = batch.service\n",
    "loss, logit = net(inputs, labels=labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.classifier.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "    {'params': net.classifier.parameters(), 'lr': 5e-5}\n",
    "], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./logs/' + datetime.today().isoformat(timespec='seconds'))\n",
    "\n",
    "def train_model(net, iterator_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    iteration = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for batch in iterator_dict[phase]:\n",
    "                inputs = batch.body[0]\n",
    "                labels = batch.service\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    loss, logit = net(input_ids=inputs, labels=labels)\n",
    "                    #print(loss, logit)\n",
    "                    _, preds = torch.max(logit, 1)\n",
    "                    #predictions.append(preds.cpu().numpy())\n",
    "                    #ground_truths.append(labels.data.cpu().numpy())\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            acc = (torch.sum(preds == labels.data)).double() / batch_size\n",
    "                            print('iteration {} || Loss: {:.4f} || acc {}'.format(\n",
    "                                iteration, loss.item(), acc.item()))\n",
    "                            writer.add_scalar(\"Loss/{}\".format(phase), loss.item(), iteration)\n",
    "                            writer.add_scalar(\"Accuracy/{}\".format(phase), acc.item(), iteration)\n",
    "                        iteration += 1\n",
    "                    \n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    #print(preds, labels.data)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = epoch_loss / len(iterator_dict[phase].dataset)\n",
    "        epoch_acc = epoch_corrects.double() / len(iterator_dict[phase].dataset)\n",
    "        writer.add_scalar(\"Loss/{}\".format(phase), epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/{}\".format(phase), epoch_acc, epoch)\n",
    "        \n",
    "        print('Epoch {}/{} | {} | Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            epoch+1, num_epochs, phase, epoch_loss, epoch_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10 || Loss: 2.0988 || acc 0.21875\n",
      "iteration 20 || Loss: 2.1861 || acc 0.125\n",
      "iteration 30 || Loss: 2.1202 || acc 0.125\n",
      "iteration 40 || Loss: 2.1214 || acc 0.09375\n",
      "iteration 50 || Loss: 2.1458 || acc 0.15625\n",
      "iteration 60 || Loss: 2.2081 || acc 0.21875\n",
      "iteration 70 || Loss: 2.0628 || acc 0.3125\n",
      "iteration 80 || Loss: 1.9948 || acc 0.21875\n",
      "iteration 90 || Loss: 2.0105 || acc 0.25\n",
      "iteration 100 || Loss: 1.9557 || acc 0.21875\n",
      "iteration 110 || Loss: 2.1051 || acc 0.25\n",
      "iteration 120 || Loss: 1.8721 || acc 0.40625\n",
      "iteration 130 || Loss: 1.7807 || acc 0.34375\n",
      "iteration 140 || Loss: 1.6750 || acc 0.375\n",
      "iteration 150 || Loss: 1.7118 || acc 0.34375\n",
      "iteration 160 || Loss: 1.4633 || acc 0.625\n",
      "iteration 170 || Loss: 1.5476 || acc 0.4375\n",
      "iteration 180 || Loss: 1.5173 || acc 0.46875\n",
      "iteration 190 || Loss: 1.0899 || acc 0.65625\n",
      "iteration 200 || Loss: 1.2870 || acc 0.65625\n",
      "iteration 210 || Loss: 1.1704 || acc 0.65625\n",
      "iteration 220 || Loss: 1.3619 || acc 0.4375\n",
      "iteration 230 || Loss: 1.1498 || acc 0.59375\n",
      "iteration 240 || Loss: 1.3926 || acc 0.5\n",
      "iteration 250 || Loss: 1.3275 || acc 0.40625\n",
      "iteration 260 || Loss: 1.1045 || acc 0.625\n",
      "iteration 270 || Loss: 1.3796 || acc 0.5625\n",
      "iteration 280 || Loss: 1.4318 || acc 0.46875\n",
      "iteration 290 || Loss: 1.4551 || acc 0.40625\n",
      "iteration 300 || Loss: 1.1847 || acc 0.625\n",
      "iteration 310 || Loss: 1.2700 || acc 0.5625\n",
      "iteration 320 || Loss: 1.0075 || acc 0.71875\n",
      "iteration 330 || Loss: 1.2799 || acc 0.53125\n",
      "iteration 340 || Loss: 1.0018 || acc 0.65625\n",
      "iteration 350 || Loss: 1.0317 || acc 0.6875\n",
      "iteration 360 || Loss: 1.2863 || acc 0.40625\n",
      "iteration 370 || Loss: 1.1244 || acc 0.625\n",
      "iteration 380 || Loss: 0.9856 || acc 0.71875\n",
      "iteration 390 || Loss: 1.1305 || acc 0.625\n",
      "iteration 400 || Loss: 1.1161 || acc 0.625\n",
      "iteration 410 || Loss: 0.8688 || acc 0.75\n",
      "iteration 420 || Loss: 0.9958 || acc 0.6875\n",
      "iteration 430 || Loss: 1.0907 || acc 0.65625\n",
      "iteration 440 || Loss: 0.9447 || acc 0.71875\n",
      "iteration 450 || Loss: 1.0724 || acc 0.65625\n",
      "iteration 460 || Loss: 0.7778 || acc 0.8125\n",
      "iteration 470 || Loss: 1.0128 || acc 0.625\n",
      "iteration 480 || Loss: 1.2025 || acc 0.53125\n",
      "iteration 490 || Loss: 0.9110 || acc 0.71875\n",
      "iteration 500 || Loss: 1.1974 || acc 0.65625\n",
      "iteration 510 || Loss: 0.9326 || acc 0.75\n",
      "iteration 520 || Loss: 0.8003 || acc 0.8125\n",
      "iteration 530 || Loss: 0.9862 || acc 0.6875\n",
      "iteration 540 || Loss: 1.4068 || acc 0.53125\n",
      "iteration 550 || Loss: 1.0428 || acc 0.65625\n",
      "iteration 560 || Loss: 0.8933 || acc 0.75\n",
      "iteration 570 || Loss: 0.8788 || acc 0.75\n",
      "iteration 580 || Loss: 1.2468 || acc 0.5625\n",
      "iteration 590 || Loss: 1.2619 || acc 0.5625\n",
      "iteration 600 || Loss: 1.3654 || acc 0.625\n",
      "iteration 610 || Loss: 1.0970 || acc 0.6875\n",
      "iteration 620 || Loss: 0.9163 || acc 0.71875\n",
      "iteration 630 || Loss: 0.9897 || acc 0.6875\n",
      "iteration 640 || Loss: 0.7792 || acc 0.71875\n",
      "iteration 650 || Loss: 1.4312 || acc 0.5\n",
      "iteration 660 || Loss: 1.0279 || acc 0.59375\n",
      "iteration 670 || Loss: 1.6359 || acc 0.46875\n",
      "iteration 680 || Loss: 0.8448 || acc 0.71875\n",
      "iteration 690 || Loss: 0.8861 || acc 0.65625\n",
      "iteration 700 || Loss: 1.5152 || acc 0.4375\n",
      "iteration 710 || Loss: 1.2080 || acc 0.5\n",
      "iteration 720 || Loss: 0.9404 || acc 0.65625\n",
      "iteration 730 || Loss: 1.4762 || acc 0.46875\n",
      "iteration 740 || Loss: 0.9537 || acc 0.6875\n",
      "iteration 750 || Loss: 1.0057 || acc 0.5\n",
      "iteration 760 || Loss: 0.9369 || acc 0.625\n",
      "iteration 770 || Loss: 0.7797 || acc 0.71875\n",
      "iteration 780 || Loss: 1.1617 || acc 0.5625\n",
      "iteration 790 || Loss: 0.9287 || acc 0.59375\n",
      "iteration 800 || Loss: 1.0015 || acc 0.6875\n",
      "iteration 810 || Loss: 0.9934 || acc 0.71875\n",
      "iteration 820 || Loss: 1.0880 || acc 0.59375\n",
      "iteration 830 || Loss: 1.0460 || acc 0.59375\n",
      "iteration 840 || Loss: 1.1133 || acc 0.65625\n",
      "iteration 850 || Loss: 0.9356 || acc 0.6875\n",
      "iteration 860 || Loss: 0.7459 || acc 0.78125\n",
      "iteration 870 || Loss: 0.9755 || acc 0.65625\n",
      "iteration 880 || Loss: 1.1353 || acc 0.5625\n",
      "iteration 890 || Loss: 0.7274 || acc 0.8125\n",
      "iteration 900 || Loss: 0.9021 || acc 0.71875\n",
      "iteration 910 || Loss: 0.8583 || acc 0.6875\n",
      "iteration 920 || Loss: 0.8357 || acc 0.65625\n",
      "iteration 930 || Loss: 1.0617 || acc 0.625\n",
      "iteration 940 || Loss: 1.1964 || acc 0.5625\n",
      "iteration 950 || Loss: 0.8016 || acc 0.75\n",
      "iteration 960 || Loss: 0.8391 || acc 0.6875\n",
      "iteration 970 || Loss: 1.1160 || acc 0.5625\n",
      "iteration 980 || Loss: 0.8674 || acc 0.71875\n",
      "iteration 990 || Loss: 0.9137 || acc 0.6875\n",
      "iteration 1000 || Loss: 0.7286 || acc 0.8125\n",
      "iteration 1010 || Loss: 0.8151 || acc 0.71875\n",
      "iteration 1020 || Loss: 0.7854 || acc 0.78125\n",
      "iteration 1030 || Loss: 0.9620 || acc 0.6875\n",
      "iteration 1040 || Loss: 0.9227 || acc 0.65625\n",
      "iteration 1050 || Loss: 0.7372 || acc 0.78125\n",
      "iteration 1060 || Loss: 0.8323 || acc 0.78125\n",
      "iteration 1070 || Loss: 0.8037 || acc 0.71875\n",
      "iteration 1080 || Loss: 1.2567 || acc 0.5625\n",
      "iteration 1090 || Loss: 1.2531 || acc 0.5625\n",
      "iteration 1100 || Loss: 0.8767 || acc 0.71875\n",
      "iteration 1110 || Loss: 0.9840 || acc 0.6875\n",
      "iteration 1120 || Loss: 0.6822 || acc 0.84375\n",
      "iteration 1130 || Loss: 1.0216 || acc 0.6875\n",
      "iteration 1140 || Loss: 1.0093 || acc 0.71875\n",
      "iteration 1150 || Loss: 1.2799 || acc 0.4375\n",
      "iteration 1160 || Loss: 0.9726 || acc 0.6875\n",
      "iteration 1170 || Loss: 0.6762 || acc 0.78125\n",
      "iteration 1180 || Loss: 1.2412 || acc 0.53125\n",
      "iteration 1190 || Loss: 0.6318 || acc 0.78125\n",
      "iteration 1200 || Loss: 0.6883 || acc 0.75\n",
      "iteration 1210 || Loss: 0.8691 || acc 0.6875\n",
      "iteration 1220 || Loss: 0.7667 || acc 0.8125\n",
      "iteration 1230 || Loss: 1.1725 || acc 0.53125\n",
      "iteration 1240 || Loss: 0.8311 || acc 0.71875\n",
      "iteration 1250 || Loss: 1.0619 || acc 0.625\n",
      "iteration 1260 || Loss: 0.5906 || acc 0.78125\n",
      "iteration 1270 || Loss: 0.9193 || acc 0.65625\n",
      "iteration 1280 || Loss: 0.7499 || acc 0.71875\n",
      "iteration 1290 || Loss: 0.9678 || acc 0.625\n",
      "iteration 1300 || Loss: 1.0288 || acc 0.625\n",
      "iteration 1310 || Loss: 0.9397 || acc 0.625\n",
      "iteration 1320 || Loss: 1.2870 || acc 0.5\n",
      "iteration 1330 || Loss: 0.8293 || acc 0.71875\n",
      "iteration 1340 || Loss: 0.9003 || acc 0.65625\n",
      "iteration 1350 || Loss: 1.1116 || acc 0.5625\n",
      "iteration 1360 || Loss: 0.8038 || acc 0.6875\n",
      "iteration 1370 || Loss: 1.0115 || acc 0.6875\n",
      "iteration 1380 || Loss: 0.7410 || acc 0.75\n",
      "iteration 1390 || Loss: 1.4293 || acc 0.40625\n",
      "iteration 1400 || Loss: 1.0320 || acc 0.59375\n",
      "iteration 1410 || Loss: 1.0863 || acc 0.65625\n",
      "Epoch 1/100 | val | Loss: 0.8332 Acc: 0.7088\n",
      "iteration 1600 || Loss: 0.6020 || acc 0.84375\n",
      "iteration 1610 || Loss: 0.9956 || acc 0.75\n",
      "iteration 1620 || Loss: 0.8402 || acc 0.6875\n",
      "iteration 1630 || Loss: 0.8964 || acc 0.75\n",
      "iteration 1640 || Loss: 0.7771 || acc 0.71875\n",
      "iteration 1650 || Loss: 0.6677 || acc 0.75\n",
      "iteration 1660 || Loss: 0.5682 || acc 0.75\n",
      "iteration 1670 || Loss: 0.9655 || acc 0.65625\n",
      "iteration 1680 || Loss: 0.9783 || acc 0.6875\n",
      "iteration 1690 || Loss: 0.6210 || acc 0.78125\n",
      "iteration 1700 || Loss: 0.7930 || acc 0.6875\n",
      "iteration 1710 || Loss: 0.6943 || acc 0.8125\n",
      "iteration 1720 || Loss: 0.8013 || acc 0.71875\n",
      "iteration 1730 || Loss: 1.1857 || acc 0.59375\n",
      "iteration 1740 || Loss: 1.3488 || acc 0.59375\n",
      "iteration 1750 || Loss: 0.8670 || acc 0.625\n",
      "iteration 1760 || Loss: 0.9255 || acc 0.59375\n",
      "iteration 1770 || Loss: 1.2369 || acc 0.59375\n",
      "iteration 1780 || Loss: 0.6490 || acc 0.84375\n",
      "iteration 1790 || Loss: 1.0497 || acc 0.53125\n",
      "iteration 1800 || Loss: 0.9404 || acc 0.6875\n",
      "iteration 1810 || Loss: 0.9052 || acc 0.65625\n",
      "iteration 1820 || Loss: 0.7020 || acc 0.84375\n",
      "iteration 1830 || Loss: 0.6736 || acc 0.84375\n",
      "iteration 1840 || Loss: 1.0840 || acc 0.625\n",
      "iteration 1850 || Loss: 1.3981 || acc 0.5\n",
      "iteration 1860 || Loss: 1.1717 || acc 0.59375\n",
      "iteration 1870 || Loss: 0.9332 || acc 0.625\n",
      "iteration 1880 || Loss: 0.8714 || acc 0.65625\n",
      "iteration 1890 || Loss: 0.8221 || acc 0.8125\n",
      "iteration 1900 || Loss: 0.7078 || acc 0.78125\n",
      "iteration 1910 || Loss: 0.7803 || acc 0.625\n",
      "iteration 1920 || Loss: 1.0043 || acc 0.59375\n",
      "iteration 1930 || Loss: 0.6489 || acc 0.78125\n",
      "iteration 1940 || Loss: 0.8840 || acc 0.65625\n",
      "iteration 1950 || Loss: 0.7957 || acc 0.71875\n",
      "iteration 1960 || Loss: 0.8729 || acc 0.65625\n",
      "iteration 1970 || Loss: 0.7916 || acc 0.78125\n",
      "iteration 1980 || Loss: 0.9054 || acc 0.6875\n",
      "iteration 1990 || Loss: 0.6091 || acc 0.84375\n",
      "iteration 2000 || Loss: 1.0062 || acc 0.65625\n",
      "iteration 2010 || Loss: 0.7573 || acc 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2020 || Loss: 0.8275 || acc 0.71875\n",
      "iteration 2030 || Loss: 1.0793 || acc 0.65625\n",
      "iteration 2040 || Loss: 1.1377 || acc 0.59375\n",
      "iteration 2050 || Loss: 0.7735 || acc 0.6875\n",
      "iteration 2060 || Loss: 0.7707 || acc 0.78125\n",
      "iteration 2070 || Loss: 0.8088 || acc 0.78125\n",
      "iteration 2080 || Loss: 1.0223 || acc 0.625\n",
      "iteration 2090 || Loss: 0.8500 || acc 0.78125\n",
      "iteration 2100 || Loss: 0.8279 || acc 0.78125\n",
      "iteration 2110 || Loss: 0.7156 || acc 0.78125\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100 \n",
    "net_trained = train_model(net, iterator_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価と比較\n",
    "\n",
    "### モデルのデプロイ\n",
    "\n",
    "## まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [(Part 1) tensorflow2でhuggingfaceのtransformersを使ってBERTを文書分類モデルに転移学習する](https://tksmml.hatenablog.com/entry/2019/10/22/215000)\n",
    "- [(Part 2) tensorflow 2 でhugging faceのtransformers公式のBERT日本語学習済みモデルを文書分類モデルにfine-tuningする](https://tksmml.hatenablog.com/entry/2019/12/15/090900)\n",
    "- [All Models and checkpoints](https://huggingface.co/models)\n",
    "- [Working with GPU packages](https://docs.anaconda.com/anaconda/user-guide/tasks/gpu-packages/)\n",
    "- [gensimとPyTorchを使ったlive doorニュースコーパスのテキスト分類](https://www.pytry3g.com/entry/2018/04/03/194202)\n",
    "- [bert-japanese](https://github.com/cl-tohoku/bert-japanese)\n",
    "- [DocumentClassificationUsingBERT-Japanese](https://github.com/nekoumei/DocumentClassificationUsingBERT-Japanese)\n",
    "- [torchtext](https://torchtext.readthedocs.io/en/latest/index.html)\n",
    "- [FX予測 : PyTorchのBERTで経済ニュース解析](https://qiita.com/THERE2/items/8b7c94787911fad8daa6)\n",
    "- [torchtextで簡単にDeepな自然言語処理](https://qiita.com/itok_msi/items/1f3746f7e89a19dafac5)\n",
    "- [transformers](https://github.com/huggingface/transformers)\n",
    "- [BERTを使った文章要約 [身内向け]](https://qiita.com/IwasakiYuuki/items/25f5bbcde4f82dff7f1a)\n",
    "- [MeCab + Gensim による日本語の自然言語処理](https://www.koi.mashykom.com/nlp.html)\n",
    "- [論文解説 Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (GNMT)](http://deeplearning.hatenablog.com/entry/gnmt)\n",
    "- [BERT with SentencePiece で日本語専用の pre-trained モデルを学習し、それを基にタスクを解く](https://techlife.cookpad.com/entry/2018/12/04/093000)\n",
    "- [はじめての自然言語処理](https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
