{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文書分類ハンズオン\n",
    "\n",
    "## 機械学習モデル開発のワークフローと本章で扱う内容\n",
    "\n",
    "なお、動作確認は以下の環境で行いました。\n",
    "\n",
    "- Machine (AWS EC2 p2.xlargeインスタンス)\n",
    "    - OS: Ubuntu 16.04\n",
    "    - CPU: Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
    "    - RAM: 64GB \n",
    "    - GPU: NVIDIA Tesla K80\n",
    "- Python\n",
    "    - Python 3.7\n",
    "    - PyTorch 1.3\n",
    "\n",
    "## 文書分類ハンズオン\n",
    "\n",
    "### 本章で扱う自然言語処理ツールの解説\n",
    "\n",
    "#### Transformers\n",
    "\n",
    "Transformersで用いることのできるモデルのリストはHugging Faceのホームページ (https://huggingface.co/models) にて公開されています。\n",
    "\n",
    "-  `bert-base-japanese`:\n",
    "-  `bert-base-japanese-whole-word-masking`\n",
    "-  `bert-base-japanese-char`\n",
    "-  `bert-base-japanese-char-whole-word-masking`\n",
    "\n",
    "Transformersは、FaceBookが開発しているPyTorchおよび、GoogleのTensorFlowのバージョン2.0以降に対応しています。ここではPyTorchを用いることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境によってインストールコマンドが異なります。https://pytorch.org/get-started/を参照してください。\n",
    "# 2019年12月現在、NVIDIAのGPUを搭載したLinuxマシンにAnacondaでPyTorchをインストールするコマンドは以下の通りです。\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# LinuxでかつGPUがない場合は !conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (4.41.0)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (1.10.45)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: click in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.45 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (1.13.45)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.45->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bert-base-japanese*` は形態素解析のライブラリとして内部でMeCabを用いているので、`mecab-python3` もインストールしておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、以降で補助的に利用するライブラリもインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (0.22)\n",
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (1.17.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Collecting matplotlib>=1.4.3\n",
      "  Using cached https://files.pythonhosted.org/packages/61/42/3e92d7aa64295483fbca20a86c89b34d0cb43cffaadaffe028793902d790/matplotlib-3.1.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/0c/fc2e007d9a992d997f04a80125b0f183da7fb554f1de701bbb70a8e7d479/pyparsing-2.4.5-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/miniconda3/envs/joki/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (42.0.2.post20191203)\n",
      "Installing collected packages: pyparsing, cycler, kiwisolver, matplotlib, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.2 pyparsing-2.4.5 seaborn-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTを用いて日本語の文章を分類する手順はおおまかに書くと以下のようになります。\n",
    "\n",
    "1. aaa\n",
    "2. aaa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['いつも',\n",
       " 'プレゼンテーション',\n",
       " 'の',\n",
       " '撮影',\n",
       " 'に',\n",
       " '無',\n",
       " '##音',\n",
       " 'カメラ',\n",
       " '##アプリ',\n",
       " 'を',\n",
       " 'ご',\n",
       " '利用',\n",
       " 'いただ',\n",
       " '##き',\n",
       " 'ありがとう',\n",
       " 'ござい',\n",
       " 'ます',\n",
       " '。']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "tokenizer.tokenize('いつもプレゼンテーションの撮影に無音カメラアプリをご利用いただきありがとうございます。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "#### livedoor ニュースコーパス\n",
    "\n",
    "今回は日本語における自然言語処理の試験用データセットとしてしばしば用いられる「livedoor ニュースコーパス」を用います。\n",
    "\n",
    "livedoorニュースはもともと株式会社ライブドアが運営するニュースサイトでしたが、株式会社ライブドアが旧ハンゲームジャパン株式会社であるNHN Japan株式会社に買収され、現在はNHN Japanが社名変更したLINE株式会社により運営されています。livedoorニュースの記事の一部には「クリエイティブ・コモンズライセンス『表示 – 改変禁止』」が適用されており、営利目的を含めて再配布可能となっています。該当するニュース記事を2012年9月上旬に株式会社ロンウイットが収集し、HTMLタグの除去などクリーニングを施した状態で公開しているのが「livedoor ニュースコーパス」です。\n",
    "\n",
    "livedoor ニュースコーパスは以下のリンクよりダウンロード可能です。\n",
    "\n",
    "https://www.rondhuit.com/download.html#ldcc\n",
    "\n",
    "オープンソースの全文検索システムApache Solrで扱いやすいようXML形式でニュースが格納されている `livedoor-news-data.tar.gz` と、シンプルに各々のニュースをテキストファイルとして扱っている `ldcc-20140209.tar.gz` が公開されています。\n",
    "\n",
    "今回は後者の `ldcc-20140209.tar.gz` をダウンロードしてください。`tar xzvf ldcc-20140209.tar.gz` などにより解凍すると `text` という名前のディレクトリが出てきます。以下のPythonスクリプトを実行するとコーパスのダウンロードと圧縮ファイルの解凍が行われ、カレントディレクトリに `text` ディレクトリが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# dataディレクトリの作成\n",
    "#os.makedirs('data', exist_ok=True)\n",
    "\n",
    "url = 'https://www.rondhuit.com/download/ldcc-20140209.tar.gz'\n",
    "file_name = 'ldcc-20140209.tar.gz'\n",
    "\n",
    "# dataディレクトリへのlivedoor ニュースコーパスのダウンロードと解凍\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    # tar.gzファイルを読み込み\n",
    "    with tarfile.open(file_name) as tar:\n",
    "        tar.extractall()\n",
    "    # tar.gzファイルを消去\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` ディレクトリの中身の構造は以下の通りです。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "├── it-life-hack\n",
    "├── kaden-channel\n",
    "├── livedoor-homme\n",
    "├── movie-enter\n",
    "├── peachy\n",
    "├── smax\n",
    "├── sports-watch\n",
    "└── topic-news\n",
    "```\n",
    "\n",
    "`dokujo-tsushin` から `topic-news` はディレクトリであり、それぞれにニュース記事のテキストが格納されています。\n",
    "\n",
    "```\n",
    "text\n",
    "├── CHANGES.txt\n",
    "├── README.txt\n",
    "├── dokujo-tsushin\n",
    "│   ├── LICENSE.txt\n",
    "│   ├── dokujo-tsushin-4778030.txt\n",
    "│   ├── dokujo-tsushin-4778031.txt\n",
    "│   ├── dokujo-tsushin-4782522.txt\n",
    "...（以下略）\n",
    "```\n",
    "\n",
    "ニュース提供元は以下の9つです。記事の本文だけを見て、その記事がどのカテゴリに属しているのか（独女通信のニュースなのか、ITライフハックのニュースなのか、など）を判別する文書分類モデルを作成するのが本章の目的です。\n",
    "\n",
    "- 独女通信 (http://news.livedoor.com/category/vender/90/)\n",
    "- ITライフハック (http://news.livedoor.com/category/vender/223/)\n",
    "- 家電チャンネル (http://news.livedoor.com/category/vender/kadench/)\n",
    "- livedoor HOMME (http://news.livedoor.com/category/vender/homme/)\n",
    "- MOVIE ENTER (http://news.livedoor.com/category/vender/movie_enter/)\n",
    "- Peachy (http://news.livedoor.com/category/vender/ldgirls/)\n",
    "- エスマックス (http://news.livedoor.com/category/vender/smax/)\n",
    "- Sports Watch (http://news.livedoor.com/category/vender/208/)\n",
    "- トピックニュース (http://news.livedoor.com/category/vender/news/)\n",
    "\n",
    "ちなみに、上記サービスのうちいくつかはドメインが変わっていたり終了しているので一部リンクが切れています。それぞれの記事ファイル（dokujo-tsushin-4778030.txtなど）は以下のフォーマットで構成されています。\n",
    "\n",
    "- １行目: 記事のURL\n",
    "- ２行目: 記事の日付\n",
    "- ３行目: 記事のタイトル\n",
    "- ４行目以降： 記事の本文\n",
    "\n",
    "このままでは少し扱いづらいのでひとつのtsv (tab-separated values) にまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news'\n",
    "]\n",
    "index = ['url', 'datetime', 'title', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dokujo-tsushin\n",
      "processing it-life-hack\n",
      "processing kaden-channel\n",
      "processing livedoor-homme\n",
      "processing movie-enter\n",
      "processing peachy\n",
      "processing smax\n",
      "processing sports-watch\n",
      "processing topic-news\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for service in services:\n",
    "    print('processing ' + service)\n",
    "    wild_card = os.path.join('text', service, '*.txt')\n",
    "    file_paths = glob.glob(wild_card)\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            series_dict = {'service': service}\n",
    "            for num, line in enumerate(lines):\n",
    "                # 改行を削除\n",
    "                line = line.replace('\\n', '')\n",
    "                if num < len(index):\n",
    "                    series_dict[index[num]] = line\n",
    "                else:\n",
    "                    series_dict['body'] += line\n",
    "            \n",
    "            s = pd.Series(series_dict)\n",
    "            df = df.append(s, ignore_index=True)\n",
    "print('done')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>service</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...</td>\n",
       "      <td>2011-10-13T15:28:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5934284/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>多くの女性が悩む「お腹の張り」。ファッション誌をめくる度に「モデルさんは細くていいなあ…」...</td>\n",
       "      <td>2010-06-25T14:00:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>まるで妊婦！？　モデルの7割が悩む「ポッコリお腹」</td>\n",
       "      <td>http://news.livedoor.com/article/detail/4848785/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>実在した武士の家計簿を元に制作された映画「武士の家計簿」。家計簿をつけ収入収支を管理し、誠実...</td>\n",
       "      <td>2011-01-04T14:00:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>つける？ つけない？ 独女の家計簿</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5247353/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>早いもので、もうすぐ季節は夏。今年は東日本を中心に、ビジネスシーンでのクールビズを例年以上に...</td>\n",
       "      <td>2011-06-22T12:30:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>夏に多発！下着チラみせ独女はアリかナシか？</td>\n",
       "      <td>http://news.livedoor.com/article/detail/5653189/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>女に必要なものは何か。一寸先は真っ暗闇の、生きるというより、生き抜かなくてはいけないこのご時...</td>\n",
       "      <td>2012-01-24T16:09:00+0900</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>東京23区女ひとり風呂 vol.04「文京区・銭湯後はこの一杯！」Presented by ...</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6218046/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  「しっかりメイクをしている顔よりも、スッピンのほうがいい」と言う男性は少なくない。しかしメイ...   \n",
       "1  　多くの女性が悩む「お腹の張り」。ファッション誌をめくる度に「モデルさんは細くていいなあ…」...   \n",
       "2  実在した武士の家計簿を元に制作された映画「武士の家計簿」。家計簿をつけ収入収支を管理し、誠実...   \n",
       "3  早いもので、もうすぐ季節は夏。今年は東日本を中心に、ビジネスシーンでのクールビズを例年以上に...   \n",
       "4  女に必要なものは何か。一寸先は真っ暗闇の、生きるというより、生き抜かなくてはいけないこのご時...   \n",
       "\n",
       "                   datetime         service  \\\n",
       "0  2011-10-13T15:28:00+0900  dokujo-tsushin   \n",
       "1  2010-06-25T14:00:00+0900  dokujo-tsushin   \n",
       "2  2011-01-04T14:00:00+0900  dokujo-tsushin   \n",
       "3  2011-06-22T12:30:00+0900  dokujo-tsushin   \n",
       "4  2012-01-24T16:09:00+0900  dokujo-tsushin   \n",
       "\n",
       "                                               title  \\\n",
       "0                   「スッピンのほうがいい」って本当？——言葉の裏に隠された男の本音   \n",
       "1                          まるで妊婦！？　モデルの7割が悩む「ポッコリお腹」   \n",
       "2                                  つける？ つけない？ 独女の家計簿   \n",
       "3                              夏に多発！下着チラみせ独女はアリかナシか？   \n",
       "4  東京23区女ひとり風呂 vol.04「文京区・銭湯後はこの一杯！」Presented by ...   \n",
       "\n",
       "                                                url  \n",
       "0  http://news.livedoor.com/article/detail/5934284/  \n",
       "1  http://news.livedoor.com/article/detail/4848785/  \n",
       "2  http://news.livedoor.com/article/detail/5247353/  \n",
       "3  http://news.livedoor.com/article/detail/5653189/  \n",
       "4  http://news.livedoor.com/article/detail/6218046/  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('news.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ラベリング\n",
    "\n",
    "### 前処理\n",
    "\n",
    "#### 形態素解析\n",
    "#### ストップワード除去\n",
    "\n",
    "### 文書分類モデル\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "net = BertForSequenceClassification.from_pretrained('bert-base-japanese-whole-word-masking', num_labels=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このニューラルネットワークの構造をnetron (https://github.com/lutzroeder/netron) というツールを用いて可視化すると次のようになります。\n",
    "<img src=\"../figures/bert_classifier_netron.png\" alt=\"bert_classifier_netron\" width=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価と比較\n",
    "\n",
    "### モデルのデプロイ\n",
    "\n",
    "## まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
